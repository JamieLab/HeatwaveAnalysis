{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "440801e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking complete. The masked data has been saved to: /Users/sayooj/Downloads/monthly_masks_masked_Tasman Sea_2015_2016.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sayooj/opt/anaconda3/envs/fe_work_env/lib/python3.7/site-packages/scipy/stats/morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/Users/sayooj/opt/anaconda3/envs/fe_work_env/lib/python3.7/site-packages/scipy/stats/morestats.py:3155: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fgco2 in Tasman Sea in 2015/2016:\n",
      "Mean p-value: 0.4758150233419608\n",
      "Mean median difference: -0.029110721834003924\n",
      "Mean standard deviation: 0.05785404956520173\n",
      "\n",
      "Results for sst in Tasman Sea in 2015/2016:\n",
      "Mean p-value: 0.4406264349675293\n",
      "Mean median difference: -0.16939254283905028\n",
      "Mean standard deviation: 0.28117283229059586\n",
      "\n",
      "Results for ph in Tasman Sea in 2015/2016:\n",
      "Mean p-value: 0.5857235574184234\n",
      "Mean median difference: 0.0005371665954589844\n",
      "Mean standard deviation: 0.0021317238840245583\n",
      "\n",
      "Results for aragonite saturation in Tasman Sea in 2015/2016:\n",
      "Mean p-value: 0.5818548200151398\n",
      "Mean median difference: 0.001022564172744751\n",
      "Mean standard deviation: 0.03514444547459073\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Define parameters for analysis\n",
    "start_year = 2015\n",
    "end_year = 2016\n",
    "num_samples = 100\n",
    "longhurst_region_code = 36\n",
    "region_name = \"Tasman Sea\"\n",
    "cat_value = 4\n",
    "\n",
    "\n",
    "# Section 1: Load and Preprocess Data\n",
    "# Load the netCDF file\n",
    "dataset = xr.open_dataset('/Users/sayooj/Downloads/GlobalAtlas_MHW_ESACCISST_1deg_1982-2021.nc', decode_times=False)\n",
    "\n",
    "# Define the start and end indices for slicing\n",
    "start_idx = (start_year - 1982) * 365\n",
    "end_idx = start_idx + (end_year - start_year + 1) * 365 - 1\n",
    "\n",
    "# Create a new dataset with data only for the specified time range\n",
    "new_dataset = dataset.isel(time=slice(start_idx, end_idx + 1))\n",
    "\n",
    "# Convert data variables to float32\n",
    "new_dataset['cat'] = new_dataset['cat'].astype('float32')\n",
    "new_dataset['mhw'] = new_dataset['mhw'].astype('float32')\n",
    "\n",
    "# Save the new dataset to a new netCDF file\n",
    "new_dataset.to_netcdf(f'/Users/sayooj/Downloads/{region_name}_{start_year}_{end_year}.nc')\n",
    "\n",
    "# Section 2: Create Monthly Masks\n",
    "# Load the netCDF file\n",
    "nc_file = nc.Dataset(f'/Users/sayooj/Downloads/{region_name}_{start_year}_{end_year}.nc', 'r')\n",
    "\n",
    "# Retrieve latitude, longitude, and time variables\n",
    "lat = nc_file.variables['lat'][:]\n",
    "lon = nc_file.variables['lon'][:]\n",
    "time = nc_file.variables['time'][:]\n",
    "cat_daily = nc_file.variables['cat'][:]\n",
    "\n",
    "# Calculate the number of months\n",
    "num_months = int(len(time) / 30)\n",
    "\n",
    "# Create an empty array to store monthly masks\n",
    "monthly_masks = np.zeros((num_months, len(lat), len(lon)))\n",
    "\n",
    "# Iterate over each month\n",
    "for month in range(num_months):\n",
    "    # Calculate the start and end indices for the current month\n",
    "    start_idx = month * 30\n",
    "    end_idx = (month + 1) * 30\n",
    "\n",
    "    # Extract the daily cat values for the current month\n",
    "    month_data = cat_daily[start_idx:end_idx]\n",
    "\n",
    "    # Find the maximum category occurrence for each lat-lon point in the current month\n",
    "    max_values = np.max(month_data, axis=0)\n",
    "\n",
    "    # Set areas impacted by the highest category occurrence\n",
    "    monthly_mask = np.where(max_values > 0, max_values, 0)\n",
    "\n",
    "    # Save the monthly mask\n",
    "    monthly_masks[month] = monthly_mask\n",
    "\n",
    "# Create a new netCDF file to save the monthly masks\n",
    "output_file = nc.Dataset(f'/Users/sayooj/Downloads/monthly_masks_{region_name}_{start_year}_{end_year}.nc', 'w')\n",
    "\n",
    "# Define dimensions in the new netCDF file\n",
    "output_file.createDimension('lat', len(lat))\n",
    "output_file.createDimension('lon', len(lon))\n",
    "output_file.createDimension('time', num_months)\n",
    "\n",
    "# Create variables in the new netCDF file\n",
    "lat_var = output_file.createVariable('lat', np.float32, ('lat',))\n",
    "lon_var = output_file.createVariable('lon', np.float32, ('lon',))\n",
    "time_var = output_file.createVariable('time', np.float64, ('time',))\n",
    "mask_var = output_file.createVariable('monthly_masks', np.int32, ('time', 'lat', 'lon'))\n",
    "\n",
    "# Assign values to variables in the new netCDF file\n",
    "lat_var[:] = lat\n",
    "lon_var[:] = lon\n",
    "time_var[:] = np.arange(1, num_months + 1)\n",
    "mask_var[:, :, :] = monthly_masks\n",
    "\n",
    "# Add attributes to variables\n",
    "lat_var.units = 'degrees_north'\n",
    "lon_var.units = 'degrees_east'\n",
    "time_var.units = 'months since {}-01-01'.format(start_year)\n",
    "mask_var.units = '1'\n",
    "\n",
    "# Add global attributes\n",
    "output_file.description = 'Monthly masks for marine heatwaves in {}'.format(region_name)\n",
    "\n",
    "# Close the new netCDF file\n",
    "output_file.close()\n",
    "\n",
    "# Close the netCDF file\n",
    "nc_file.close()\n",
    "\n",
    "# Section 3: Mask Based on Longhurst Regions\n",
    "# Open the Longhurst region file\n",
    "longhurst_file = '/Users/sayooj/Downloads/Longhurst_1_deg.nc'\n",
    "longhurst_dataset = nc.Dataset(longhurst_file)\n",
    "\n",
    "# Read the Longhurst variable\n",
    "longhurst = longhurst_dataset.variables['longhurst'][:]\n",
    "\n",
    "# Open the monthly masks file\n",
    "monthly_mask_file = f'/Users/sayooj/Downloads/monthly_masks_{region_name}_{start_year}_{end_year}.nc'\n",
    "monthly_mask_dataset = nc.Dataset(monthly_mask_file)\n",
    "\n",
    "# Read the monthly masks variable\n",
    "monthly_masks = monthly_mask_dataset.variables['monthly_masks'][:]\n",
    "\n",
    "# Create a mask based on Longhurst regions and transpose it\n",
    "mask = np.isin(longhurst, [longhurst_region_code]).T\n",
    "\n",
    "# Apply the mask to each time step individually\n",
    "masked_monthly_masks = np.where(mask, monthly_masks, np.nan)\n",
    "\n",
    "# Get dimensions from the original dataset\n",
    "lat = monthly_mask_dataset.variables['lat'][:]\n",
    "lon = monthly_mask_dataset.variables['lon'][:]\n",
    "time = monthly_mask_dataset.variables['time'][:]\n",
    "\n",
    "# Close the netCDF files\n",
    "longhurst_dataset.close()\n",
    "monthly_mask_dataset.close()\n",
    "\n",
    "# Save the masked data to a new netCDF file\n",
    "masked_file_path = f'/Users/sayooj/Downloads/monthly_masks_masked_{region_name}_{start_year}_{end_year}.nc'\n",
    "with nc.Dataset(masked_file_path, 'w') as masked_dataset:\n",
    "    # Create dimensions\n",
    "    masked_dataset.createDimension('lat', len(lat))\n",
    "    masked_dataset.createDimension('lon', len(lon))\n",
    "    masked_dataset.createDimension('time', len(time))\n",
    "\n",
    "    # Create variables\n",
    "    masked_lat = masked_dataset.createVariable('lat', 'float', ('lat',))\n",
    "    masked_lat.units = 'degrees_north'\n",
    "    masked_lon = masked_dataset.createVariable('lon', 'float', ('lon',))\n",
    "    masked_lon.units = 'degrees_east'\n",
    "    masked_time = masked_dataset.createVariable('time', 'double', ('time',))\n",
    "\n",
    "    masked_monthly_masks_var = masked_dataset.createVariable('monthly_masks', 'float', ('time', 'lat', 'lon'),\n",
    "                                                           fill_value=np.nan)  # Use an appropriate fill value\n",
    "\n",
    "    # Assign values to variables\n",
    "    masked_lat[:] = lat\n",
    "    masked_lon[:] = lon\n",
    "    masked_time[:] = time\n",
    "    masked_monthly_masks_var[:] = np.where(masked_monthly_masks != -2147483648.0, masked_monthly_masks, np.nan)\n",
    "\n",
    "    masked_monthly_masks_var.min = 1\n",
    "    masked_monthly_masks_var.max = cat_value\n",
    "\n",
    "print(\"Masking complete. The masked data has been saved to:\", masked_file_path)\n",
    "\n",
    "# Section 4: Statistical Analysis\n",
    "# Open the dataset file\n",
    "dataset_file = nc.Dataset('/Users/sayooj/Downloads/OceanSODA-ETHZ_GRaCER_v2021a_1982-2020.nc')\n",
    "\n",
    "# Get the variable data\n",
    "fgco2 = dataset_file.variables['fgco2'][:]\n",
    "ph = dataset_file.variables['ph_total'][:]\n",
    "aragonite_saturation = dataset_file.variables['omega_ar'][:]\n",
    "sst = dataset_file.variables['temperature'][:]\n",
    "\n",
    "# Create the time axis for the specified years\n",
    "dates = pd.date_range(start='{}-01-01'.format(start_year), end='{}-12-31'.format(end_year), freq='M')\n",
    "\n",
    "# Find the indices corresponding to the time period\n",
    "indices_year = np.where(dates.year.isin([start_year, end_year]))[0]\n",
    "\n",
    "# Slice the data for the specified years\n",
    "fgco2_year = fgco2[indices_year]\n",
    "sst_year = sst[indices_year]\n",
    "ph_year = ph[indices_year]\n",
    "aragonite_saturation_year = aragonite_saturation[indices_year]\n",
    "\n",
    "# Open the mask file for the specified region\n",
    "mask_file = nc.Dataset(f'/Users/sayooj/Downloads/monthly_masks_masked_{region_name}_{start_year}_{end_year}.nc')\n",
    "\n",
    "# Get the mask variable for the specified region\n",
    "mask_region = mask_file.variables['monthly_masks'][:]\n",
    "\n",
    "# Apply the mask to the sliced data\n",
    "fgco2_masked_year = np.ma.masked_array(fgco2_year, np.logical_not(mask_region))\n",
    "sst_masked_year = np.ma.masked_array(sst_year, np.logical_not(mask_region))\n",
    "ph_masked_year = np.ma.masked_array(ph_year, np.logical_not(mask_region))\n",
    "aragonite_saturation_masked_year = np.ma.masked_array(aragonite_saturation_year, np.logical_not(mask_region))\n",
    "\n",
    "# Calculate median values with the mask\n",
    "fgco2_median_region_year = np.ma.median(fgco2_masked_year, axis=(1, 2))\n",
    "sst_median_region_year = np.ma.median(sst_masked_year, axis=(1, 2))\n",
    "ph_median_region_year = np.ma.median(ph_masked_year, axis=(1, 2))\n",
    "aragonite_saturation_median_region_year = np.ma.median(aragonite_saturation_masked_year, axis=(1, 2))\n",
    "\n",
    "# Get indices where the mask values are equal to the specified category value (e.g., heatwave period)\n",
    "indices_heatwave_region_year = np.where(mask_region == cat_value)[0]\n",
    "\n",
    "# Get indices where the mask values are not equal to the specified category value (e.g., non-heatwave period)\n",
    "indices_non_heatwave_region_year = np.where(mask_region != cat_value)[0]\n",
    "\n",
    "# Perform the Wilcoxon signed-rank tests for each variable\n",
    "p_values_region_year = []\n",
    "median_diff_region_year = []\n",
    "std_dev_region_year = []\n",
    "\n",
    "# Perform the Wilcoxon signed-rank tests for fgco2\n",
    "for _ in range(num_samples):\n",
    "    # Randomly select indices for heatwave and non-heatwave periods\n",
    "    sample_indices_region_heatwave_year = np.random.choice(indices_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "    sample_indices_region_non_heatwave_year = np.random.choice(indices_non_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "\n",
    "    # Filter the data based on the sampled indices\n",
    "    sample_fgco2_median_region_heatwave_year = fgco2_median_region_year[sample_indices_region_heatwave_year]\n",
    "    sample_fgco2_median_region_non_heatwave_year = fgco2_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "    # Perform the Wilcoxon signed-rank tests\n",
    "    _, p_value_region_year = wilcoxon(sample_fgco2_median_region_heatwave_year, sample_fgco2_median_region_non_heatwave_year)\n",
    "\n",
    "    # Calculate the median difference and standard deviation\n",
    "    median_diff_region_year.append(np.median(sample_fgco2_median_region_heatwave_year - sample_fgco2_median_region_non_heatwave_year))\n",
    "    std_dev_region_year.append(np.std(sample_fgco2_median_region_heatwave_year - sample_fgco2_median_region_non_heatwave_year))\n",
    "\n",
    "    # Append the p-value to the respective list\n",
    "    p_values_region_year.append(p_value_region_year)\n",
    "\n",
    "# Calculate the mean p-value, median difference, and standard deviation for fgco2\n",
    "mean_p_value_fgco2_region_year = np.mean(p_values_region_year)\n",
    "mean_median_diff_fgco2_region_year = np.mean(median_diff_region_year)\n",
    "mean_std_dev_fgco2_region_year = np.mean(std_dev_region_year)\n",
    "\n",
    "# Perform the Wilcoxon signed-rank tests for sst\n",
    "p_values_region_year = []\n",
    "median_diff_region_year = []\n",
    "std_dev_region_year = []\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    # Randomly select indices for heatwave and non-heatwave periods\n",
    "    sample_indices_region_heatwave_year = np.random.choice(indices_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "    sample_indices_region_non_heatwave_year = np.random.choice(indices_non_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "\n",
    "    # Filter the data based on the sampled indices\n",
    "    sample_sst_median_region_heatwave_year = sst_median_region_year[sample_indices_region_heatwave_year]\n",
    "    sample_sst_median_region_non_heatwave_year = sst_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "    # Perform the Wilcoxon signed-rank tests\n",
    "    _, p_value_region_year = wilcoxon(sample_sst_median_region_heatwave_year, sample_sst_median_region_non_heatwave_year)\n",
    "\n",
    "    # Calculate the median difference and standard deviation\n",
    "    median_diff_region_year.append(np.median(sample_sst_median_region_heatwave_year - sample_sst_median_region_non_heatwave_year))\n",
    "    std_dev_region_year.append(np.std(sample_sst_median_region_heatwave_year - sample_sst_median_region_non_heatwave_year))\n",
    "\n",
    "    # Append the p-value to the respective list\n",
    "    p_values_region_year.append(p_value_region_year)\n",
    "\n",
    "# Calculate the mean p-value, median difference, and standard deviation for sst\n",
    "mean_p_value_sst_region_year = np.mean(p_values_region_year)\n",
    "mean_median_diff_sst_region_year = np.mean(median_diff_region_year)\n",
    "mean_std_dev_sst_region_year = np.mean(std_dev_region_year)\n",
    "\n",
    "# Perform the Wilcoxon signed-rank tests for ph\n",
    "p_values_region_year = []\n",
    "median_diff_region_year = []\n",
    "std_dev_region_year = []\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    # Randomly select indices for heatwave and non-heatwave periods\n",
    "    sample_indices_region_heatwave_year = np.random.choice(indices_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "    sample_indices_region_non_heatwave_year = np.random.choice(indices_non_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "\n",
    "    # Filter the data based on the sampled indices\n",
    "    sample_ph_median_region_heatwave_year = ph_median_region_year[sample_indices_region_heatwave_year]\n",
    "    sample_ph_median_region_non_heatwave_year = ph_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "    # Perform the Wilcoxon signed-rank tests\n",
    "    _, p_value_region_year = wilcoxon(sample_ph_median_region_heatwave_year, sample_ph_median_region_non_heatwave_year)\n",
    "\n",
    "    # Calculate the median difference and standard deviation\n",
    "    median_diff_region_year.append(np.median(sample_ph_median_region_heatwave_year - sample_ph_median_region_non_heatwave_year))\n",
    "    std_dev_region_year.append(np.std(sample_ph_median_region_heatwave_year - sample_ph_median_region_non_heatwave_year))\n",
    "\n",
    "    # Append the p-value to the respective list\n",
    "    p_values_region_year.append(p_value_region_year)\n",
    "\n",
    "# Calculate the mean p-value, median difference, and standard deviation for ph\n",
    "mean_p_value_ph_region_year = np.mean(p_values_region_year)\n",
    "mean_median_diff_ph_region_year = np.mean(median_diff_region_year)\n",
    "mean_std_dev_ph_region_year = np.mean(std_dev_region_year)\n",
    "\n",
    "# Perform the Wilcoxon signed-rank tests for aragonite saturation\n",
    "p_values_region_year = []\n",
    "median_diff_region_year = []\n",
    "std_dev_region_year = []\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    # Randomly select indices for heatwave and non-heatwave periods\n",
    "    sample_indices_region_heatwave_year = np.random.choice(indices_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "    sample_indices_region_non_heatwave_year = np.random.choice(indices_non_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "\n",
    "    # Filter the data based on the sampled indices\n",
    "    sample_aragonite_saturation_median_region_heatwave_year = aragonite_saturation_median_region_year[sample_indices_region_heatwave_year]\n",
    "    sample_aragonite_saturation_median_region_non_heatwave_year = aragonite_saturation_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "    # Perform the Wilcoxon signed-rank tests\n",
    "    _, p_value_region_year = wilcoxon(sample_aragonite_saturation_median_region_heatwave_year, sample_aragonite_saturation_median_region_non_heatwave_year)\n",
    "\n",
    "    # Calculate the median difference and standard deviation\n",
    "    median_diff_region_year.append(np.median(sample_aragonite_saturation_median_region_heatwave_year - sample_aragonite_saturation_median_region_non_heatwave_year))\n",
    "    std_dev_region_year.append(np.std(sample_aragonite_saturation_median_region_heatwave_year - sample_aragonite_saturation_median_region_non_heatwave_year))\n",
    "\n",
    "    # Append the p-value to the respective list\n",
    "    p_values_region_year.append(p_value_region_year)\n",
    "\n",
    "# Calculate the mean p-value, median difference, and standard deviation for aragonite saturation\n",
    "mean_p_value_aragonite_saturation_region_year = np.mean(p_values_region_year)\n",
    "mean_median_diff_aragonite_saturation_region_year = np.mean(median_diff_region_year)\n",
    "mean_std_dev_aragonite_saturation_region_year = np.mean(std_dev_region_year)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Results for fgco2 in {region_name} in {start_year}/{end_year}:\")\n",
    "print(\"Mean p-value:\", mean_p_value_fgco2_region_year)\n",
    "print(\"Mean median difference:\", mean_median_diff_fgco2_region_year)\n",
    "print(\"Mean standard deviation:\", mean_std_dev_fgco2_region_year)\n",
    "\n",
    "print(f\"\\nResults for sst in {region_name} in {start_year}/{end_year}:\")\n",
    "print(\"Mean p-value:\", mean_p_value_sst_region_year)\n",
    "print(\"Mean median difference:\", mean_median_diff_sst_region_year)\n",
    "print(\"Mean standard deviation:\", mean_std_dev_sst_region_year)\n",
    "\n",
    "print(f\"\\nResults for ph in {region_name} in {start_year}/{end_year}:\")\n",
    "print(\"Mean p-value:\", mean_p_value_ph_region_year)\n",
    "print(\"Mean median difference:\", mean_median_diff_ph_region_year)\n",
    "print(\"Mean standard deviation:\", mean_std_dev_ph_region_year)\n",
    "\n",
    "print(f\"\\nResults for aragonite saturation in {region_name} in {start_year}/{end_year}:\")\n",
    "print(\"Mean p-value:\", mean_p_value_aragonite_saturation_region_year)\n",
    "print(\"Mean median difference:\", mean_median_diff_aragonite_saturation_region_year)\n",
    "print(\"Mean standard deviation:\", mean_std_dev_aragonite_saturation_region_year)\n",
    "\n",
    "# Close the netCDF files\n",
    "dataset_file.close()\n",
    "mask_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f6747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

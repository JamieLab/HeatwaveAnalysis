{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section should only be run if you don't have file for monthly averages for all biological variables\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "# Open the chlorophyll NetCDF file\n",
    "chlorophyll_file = xr.open_dataset('/Users/Sayooj/Downloads/Sayooj_OC-CCI_chl-a_CCMP_wind/OC-CCI_chlor_a_1997_2022.nc')\n",
    "\n",
    "# Open the wind speed and direction NetCDF file\n",
    "wind_file = xr.open_dataset('/Users/Sayooj/Downloads/Sayooj_OC-CCI_chl-a_CCMP_wind/CCMP_v3.0_wind_1993_2019.nc')\n",
    "\n",
    "# List of variables\n",
    "variables = ['OC-CCI_chlor_a', 'CCMP_w', 'CCMP_wind_dir']\n",
    "\n",
    "# Create an empty dataset to store the monthly averages for all variables\n",
    "monthly_avg_dataset = xr.Dataset()\n",
    "\n",
    "# Loop over each variable\n",
    "for variable in variables:\n",
    "    # Extract the variable data\n",
    "    if variable == 'OC-CCI_chlor_a':\n",
    "        var_data = chlorophyll_file[variable]\n",
    "    else:\n",
    "        var_data = wind_file[variable]\n",
    "\n",
    "    # Resample to monthly frequency and calculate the mean for each month\n",
    "    monthly_avg = var_data.resample(time='M').mean(dim='time')\n",
    "\n",
    "    # Calculate the overall average for each month across all years\n",
    "    monthly_avg_overall = monthly_avg.groupby('time.month').mean(dim='time')\n",
    "\n",
    "    # Add the variable to the combined dataset\n",
    "    monthly_avg_dataset[variable] = monthly_avg_overall\n",
    "\n",
    "# Save the combined dataset to a new NetCDF file\n",
    "output_path = '/Users/Sayooj/Downloads/all_biologicalvariables_monthly_avg_overall.nc'\n",
    "monthly_avg_dataset.to_netcdf(output_path)\n",
    "print(f'Saved all variables monthly averages to {output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a0963e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliced chlorophyll dataset saved to D:/OceanHealth/output/sliced_OC-CCI_chlor_a_ANTA3_2016_2017.nc\n",
      "Sliced wind dataset saved to D:/OceanHealth/output/sliced_OC-CCI_CCMP_v3.0_wind_ANTA3_2016_2017.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\df391\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\numpy\\core\\fromnumeric.py:771: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  a.partition(kth, axis=axis, kind=kind, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for chlorophyll in ANTA for 2016/2017 for 1 months after a consecutive period of 3 months:\n",
      "Median p-value: 8.723882774225123e-36\n",
      "Median median difference: -0.0019401460886001587\n",
      "Median standard deviation: 0.05128878976517984\n",
      "Results for wind speed in ANTA for 2016/2017 for 1 months after a consecutive period of 3 months:\n",
      "Median p-value: 0.6677912707001687\n",
      "Median median difference: 0.0\n",
      "Median standard deviation: 0.19327442894814098\n",
      "Results for wind direction in ANTA for 2016/2017 for 1 months after a consecutive period of 3 months:\n",
      "Median p-value: 1.0059351835268644e-25\n",
      "Median median difference: -0.554718017578125\n",
      "Median standard deviation: 30.825468463366516\n",
      "Results in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results appended to D:/OceanHealth/output/results_cat_3_4.csv\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: b'D:\\\\OceanHealth\\\\output\\\\consecutive_monthly_mask_ANTA3_2016_2017.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\xarray\\backends\\file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\xarray\\backends\\lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('D:\\\\OceanHealth\\\\output\\\\consecutive_monthly_mask_ANTA3_2016_2017.nc',), 'a', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), 'fe504dbc-14ec-4735-9dfc-02794ac9d757']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 180\u001b[0m\n\u001b[0;32m    177\u001b[0m consecutive_monthly_mask_file\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConsecutive monthly mask for values 3 or 4 in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# Save the consecutive monthly mask to a new netCDF file\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m \u001b[43mconsecutive_monthly_mask_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_loc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconsecutive_monthly_mask_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mregion_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mconsecutive_months_threshold\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstart_year\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mend_year\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Close the netCDF files\u001b[39;00m\n\u001b[0;32m    183\u001b[0m monthly_masks_file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\xarray\\core\\dataset.py:1957\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[1;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf)\u001b[0m\n\u001b[0;32m   1954\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1955\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[1;32m-> 1957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[0;32m   1958\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1961\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1965\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\xarray\\backends\\api.py:1255\u001b[0m, in \u001b[0;36mto_netcdf\u001b[1;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1252\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1253\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized option \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid_netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1254\u001b[0m         )\n\u001b[1;32m-> 1255\u001b[0m store \u001b[38;5;241m=\u001b[39m store_open(target, mode, \u001b[38;5;28mformat\u001b[39m, group, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unlimited_dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1258\u001b[0m     unlimited_dims \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mencoding\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munlimited_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:391\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[1;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[0;32m    385\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    386\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[0;32m    387\u001b[0m )\n\u001b[0;32m    388\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[0;32m    389\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[0;32m    390\u001b[0m )\n\u001b[1;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:338\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[1;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:400\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:394\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[0;32m    395\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\OceanHealth\\lib\\contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\xarray\\backends\\file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\xarray\\backends\\file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[1;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opener(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32msrc\\netCDF4\\_netCDF4.pyx:2463\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\netCDF4\\_netCDF4.pyx:2026\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: b'D:\\\\OceanHealth\\\\output\\\\consecutive_monthly_mask_ANTA3_2016_2017.nc'"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "# Read parameter combinations from CSV file\n",
    "csv_file_path = \"C:/Users/df391/OneDrive - University of Exeter/Post_Doc_Ocean_Health/HeatwaveAnalysis/PARAMETERS.csv\"  # Replace with the actual path DJF: Edited path 16/05/2024\n",
    "heatwave_file = \"D:/OceanHealth/GlobalAtlas_MHW_ESACCISST_1deg_1982-2021.nc\"\n",
    "longhurst_file = 'D:/OceanHealth/Longhurst_1_deg.nc'\n",
    "file_path_chlorophyll = 'D:/OceanHealth/Sayooj_OC-CCI_chl-a_CCMP_wind/OC-CCI_chlor_a_1997_2022.nc'\n",
    "file_path_wind = 'D:/OceanHealth/Sayooj_OC-CCI_chl-a_CCMP_wind/CCMP_v3.0_wind_1993_2019.nc'\n",
    "file_nonheatwave = 'D:/OceanHealth/all_biologicalvariables_monthly_avg_overall.nc'\n",
    "output_loc = 'D:/OceanHealth/output/'\n",
    "\n",
    "parameters_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Remove extra spaces from column names\n",
    "parameters_df.columns = parameters_df.columns.str.strip()\n",
    "\n",
    "for index, row in parameters_df.iterrows():\n",
    "    start_year = row['start_year']\n",
    "    end_year = row['end_year']\n",
    "    longhurst_region_code = row['longhurst_region_code']\n",
    "    region_name = row['region_name']\n",
    "    combined_cat_values = [3, 4]\n",
    "    num_samples = row['num_samples']\n",
    "    consecutive_months_threshold = row['consecutive_months_threshold']\n",
    "    months_after = row['months_after']\n",
    "\n",
    "    # Section 1: Load and Preprocess Data\n",
    "    # Load the netCDF file containing variables other than chlorophyll\n",
    "    dataset = xr.open_dataset(heatwave_file, decode_times=False)\n",
    "\n",
    "    # Define the start and end indices for slicing\n",
    "    start_idx = (start_year - 1982) * 365\n",
    "    end_idx = start_idx + (end_year - start_year + 1) * 365 - 1\n",
    "\n",
    "    # Create a new dataset with data only for the specified time range\n",
    "    new_dataset = dataset.isel(time=slice(start_idx, end_idx + 1))\n",
    "\n",
    "    # Convert data variables to float32 if needed\n",
    "    new_dataset['cat'] = new_dataset['cat'].astype('float32')\n",
    "    new_dataset['mhw'] = new_dataset['mhw'].astype('float32')\n",
    "\n",
    "    # Save the new dataset to a new netCDF file\n",
    "    new_dataset.to_netcdf(output_loc+f'{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Section 2: Mask Based on Longhurst Regions\n",
    "    # Open the Longhurst region file\n",
    "    #longhurst_file = '/Users/sayooj/Downloads/Longhurst_1_deg.nc'\n",
    "    longhurst_dataset = xr.open_dataset(longhurst_file)\n",
    "\n",
    "    # Read the Longhurst variable\n",
    "    longhurst = longhurst_dataset['longhurst'].values\n",
    "\n",
    "    # Create a mask based on Longhurst regions and transpose it\n",
    "    mask = np.isin(longhurst, [longhurst_region_code]).T\n",
    "\n",
    "    # Apply the mask to the entire time range\n",
    "    masked_dataset = new_dataset.where(mask)\n",
    "\n",
    "    # Save the masked data to a new netCDF file\n",
    "    masked_file_path = output_loc + f'masked_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc'\n",
    "    masked_dataset.to_netcdf(masked_file_path)\n",
    "\n",
    "    # Section 3: Create Monthly Masks with Values Only Inside Longhurst Region\n",
    "    # Load the netCDF file containing the masked data\n",
    "    masked_nc_file = xr.open_dataset(masked_file_path, decode_times=False)\n",
    "\n",
    "    # Extract the masked cat variable and apply the Longhurst mask\n",
    "    masked_cat = masked_nc_file['cat'].where(mask)\n",
    "\n",
    "    # Calculate the number of months\n",
    "    num_months = int(len(masked_nc_file['time']) / 30)\n",
    "\n",
    "    # Create an empty array to store monthly masks\n",
    "    monthly_masks = np.zeros((num_months, len(masked_nc_file['lat']), len(masked_nc_file['lon']))) * np.nan\n",
    "\n",
    "    # Iterate over each month\n",
    "    for month in range(num_months):\n",
    "        # Calculate the start and end indices for the current month\n",
    "        start_idx = month * 30\n",
    "        end_idx = (month + 1) * 30\n",
    "\n",
    "        # Extract the masked daily cat values for the current month\n",
    "        month_data = masked_cat[start_idx:end_idx]\n",
    "\n",
    "        # Find the maximum category occurrence for each lat-lon point in the current month\n",
    "        max_values = np.max(month_data, axis=0)\n",
    "\n",
    "        # Set areas impacted by the highest category occurrence within the Longhurst region\n",
    "        monthly_mask = np.where(mask, max_values, np.nan)\n",
    "\n",
    "        # Save the monthly mask\n",
    "        monthly_masks[month] = monthly_mask\n",
    "\n",
    "    # Create a new netCDF file to save the monthly masks\n",
    "    output_file = xr.Dataset(\n",
    "        data_vars={\n",
    "            'lat': ('lat', masked_nc_file['lat'].values),\n",
    "            'lon': ('lon', masked_nc_file['lon'].values),\n",
    "            'time': ('time', np.arange(1, num_months + 1)),\n",
    "            'monthly_masks': (['time', 'lat', 'lon'], monthly_masks)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add attributes\n",
    "    output_file['lat'].attrs['units'] = 'degrees_north'\n",
    "    output_file['lon'].attrs['units'] = 'degrees_east'\n",
    "    output_file['time'].attrs['units'] = f'months since {start_year}-01-01'\n",
    "    output_file['monthly_masks'].attrs['units'] = '1'\n",
    "    output_file.attrs['description'] = f'Monthly masks for marine heatwaves in {region_name}'\n",
    "\n",
    "    # Save the monthly masks to a new netCDF file\n",
    "    output_file.to_netcdf(output_loc + f'monthly_masks_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Close the netCDF files\n",
    "    masked_nc_file.close()\n",
    "\n",
    "    # Section 4: Create Consecutive Monthly Mask for Values 3 or 4\n",
    "    # Load the netCDF file containing the monthly masks\n",
    "    monthly_masks_file = xr.open_dataset(output_loc + f'monthly_masks_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc', decode_times=False)\n",
    "\n",
    "    # Extract the monthly masks variable\n",
    "    monthly_masks_data = monthly_masks_file['monthly_masks'].values\n",
    "\n",
    "    # Initialize the consecutive monthly mask array\n",
    "    consecutive_monthly_mask = np.zeros_like(monthly_masks) * np.nan\n",
    "\n",
    "    # Iterate over each lat-lon point\n",
    "    for lat_idx in range(monthly_masks_data.shape[1]):\n",
    "        for lon_idx in range(monthly_masks_data.shape[2]):\n",
    "            # Extract the monthly mask values for the current lat-lon point\n",
    "            values = monthly_masks_data[:, lat_idx, lon_idx]\n",
    "\n",
    "            consecutive_count = 0\n",
    "            consecutive_mask = np.zeros_like(values)\n",
    "\n",
    "            for i in range(len(values)):\n",
    "                if (values[i] == 3) or (values[i] == 4):\n",
    "                    consecutive_count += 1\n",
    "                    consecutive_mask[i] = values[i]\n",
    "                else:\n",
    "                    consecutive_count = 0\n",
    "                    consecutive_mask[i] = 0\n",
    "\n",
    "                if consecutive_count >= consecutive_months_threshold:\n",
    "                    break\n",
    "\n",
    "            # Set the consecutive monthly mask values for the current lat-lon point\n",
    "            consecutive_monthly_mask[:len(consecutive_mask), lat_idx, lon_idx] = consecutive_mask\n",
    "\n",
    "    # Apply the Longhurst mask to set values inside the region to NaN\n",
    "    consecutive_monthly_mask = np.where(mask, consecutive_monthly_mask, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "    # Create a new netCDF file to save the consecutive monthly mask\n",
    "    consecutive_monthly_mask_file = xr.Dataset(\n",
    "        data_vars={\n",
    "            'lat': ('lat', monthly_masks_file['lat'].values),\n",
    "            'lon': ('lon', monthly_masks_file['lon'].values),\n",
    "            'time': ('time', monthly_masks_file['time'].values),\n",
    "            'consecutive_monthly_mask': (['time', 'lat', 'lon'], consecutive_monthly_mask)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add attributes\n",
    "    consecutive_monthly_mask_file['lat'].attrs['units'] = 'degrees_north'\n",
    "    consecutive_monthly_mask_file['lon'].attrs['units'] = 'degrees_east'\n",
    "    consecutive_monthly_mask_file['time'].attrs['units'] = f'months since {start_year}-01-01'\n",
    "    consecutive_monthly_mask_file['consecutive_monthly_mask'].attrs['units'] = '1'\n",
    "    consecutive_monthly_mask_file.attrs['description'] = f'Consecutive monthly mask for values 3 or 4 in {region_name}'\n",
    "\n",
    "    # Save the consecutive monthly mask to a new netCDF file\n",
    "    consecutive_monthly_mask_file.to_netcdf(output_loc + f'consecutive_monthly_mask_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Close the netCDF files\n",
    "    monthly_masks_file.close()\n",
    "    consecutive_monthly_mask_file.close()\n",
    "\n",
    "    # Initialize a list to store information about consecutive heatwaves\n",
    "    consecutive_heatwave_info = []\n",
    "\n",
    "    # Iterate over each lat-lon point\n",
    "    for lat_idx in range(consecutive_monthly_mask.shape[1]):\n",
    "        for lon_idx in range(consecutive_monthly_mask.shape[2]):\n",
    "            # Extract the consecutive monthly mask values for the current lat-lon point\n",
    "            values = consecutive_monthly_mask[:, lat_idx, lon_idx]\n",
    "\n",
    "            # Find indices where consecutive heatwaves occurred (values 3 or 4)\n",
    "            heatwave_indices = np.where(np.isin(values, [3, 4]))[0]\n",
    "\n",
    "            # If consecutive heatwaves occurred at this lat-lon point\n",
    "            if len(heatwave_indices) >= consecutive_months_threshold:\n",
    "                # Get the corresponding dates for the identified indices\n",
    "                heatwave_dates = monthly_masks_file['time'].values[heatwave_indices]\n",
    "\n",
    "                # Convert months to dates based on the start_year\n",
    "                start_date = pd.to_datetime(f'{start_year}-01-01')\n",
    "                exact_dates = [(start_date + pd.DateOffset(months=int(month))).strftime('%Y-%m-%d') for month in heatwave_dates]\n",
    "\n",
    "                # Append the lat, lon, months, and exact_dates to the list\n",
    "                consecutive_heatwave_info.append({\n",
    "                    'lat': monthly_masks_file['lat'].values[lat_idx],\n",
    "                    'lon': monthly_masks_file['lon'].values[lon_idx],\n",
    "                    'months': heatwave_dates.tolist(),\n",
    "                    'exact_dates': exact_dates\n",
    "                })\n",
    "\n",
    "    # Create a DataFrame with the extracted information\n",
    "    consecutive_heatwave_info_df = pd.DataFrame(consecutive_heatwave_info)\n",
    "\n",
    "    # Save the DataFrame to a CSV file with region name, start year, and end year in the filename\n",
    "    csv_file_path = output_loc+f'consecutive_heatwave_info_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.csv'\n",
    "    consecutive_heatwave_info_df.to_csv(csv_file_path, index=False)\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    consecutive_heatwave_info_df = pd.read_csv(output_loc + f'consecutive_heatwave_info_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.csv')\n",
    "\n",
    "    # Convert the 'exact_dates' column from string to list of datetime objects\n",
    "    consecutive_heatwave_info_df['exact_dates'] = consecutive_heatwave_info_df['exact_dates'].apply(eval)\n",
    "    consecutive_heatwave_info_df['exact_dates'] = consecutive_heatwave_info_df['exact_dates'].apply(lambda dates: [pd.to_datetime(date).date() for date in dates])\n",
    "\n",
    "    # Extract the date portion from the third date in each list of exact dates\n",
    "    third_dates = consecutive_heatwave_info_df['exact_dates'].apply(lambda dates: dates[2])\n",
    "\n",
    "    # Find the min and max date among the extracted third dates\n",
    "    hw_first_date = min(third_dates)\n",
    "    hw_last_date = max(third_dates)\n",
    "\n",
    "\n",
    "    # Open the existing NetCDF file for chlorophyll data\n",
    "    #file_path_chlorophyll = ('/Users/Sayooj/Downloads/Sayooj_OC-CCI_chl-a_CCMP_wind/OC-CCI_chlor_a_1997_2022.nc')\n",
    "\n",
    "    ds_chlorophyll = xr.open_dataset(file_path_chlorophyll)\n",
    "\n",
    "    # Define the time range you want to slice for chlorophyll data\n",
    "    start_date_chlorophyll = f'{start_year}-01-01'\n",
    "    end_date_chlorophyll = f'{end_year}-12-31'\n",
    "\n",
    "    # Slice the chlorophyll dataset to the desired time range\n",
    "    ds_chlorophyll_sliced = ds_chlorophyll.sel(time=slice(start_date_chlorophyll, end_date_chlorophyll))\n",
    "\n",
    "    # Create a new NetCDF file for sliced chlorophyll data\n",
    "    output_file_path_chlorophyll = output_loc+f'sliced_OC-CCI_chlor_a_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc'\n",
    "    ds_chlorophyll_sliced.to_netcdf(output_file_path_chlorophyll)\n",
    "\n",
    "    # Close the original and sliced chlorophyll datasets\n",
    "    ds_chlorophyll.close()\n",
    "    ds_chlorophyll_sliced.close()\n",
    "\n",
    "    print(f'Sliced chlorophyll dataset saved to {output_file_path_chlorophyll}')\n",
    "\n",
    "    # Open the existing NetCDF file for wind speed and direction data\n",
    "    #file_path_wind = '/Users/Sayooj/Downloads/Sayooj_OC-CCI_chl-a_CCMP_wind/CCMP_v3.0_wind_1993_2019.nc'\n",
    "    ds_wind = xr.open_dataset(file_path_wind)\n",
    "\n",
    "    # Calculate the start and end dates based on start_year and end_year\n",
    "    start_date_wind = f'{start_year}-01-01'\n",
    "    end_date_wind = f'{end_year}-12-31'\n",
    "\n",
    "    # Slice the wind dataset to the calculated time range\n",
    "    ds_wind_sliced = ds_wind.sel(time=slice(start_date_wind, end_date_wind))\n",
    "\n",
    "    # Create a new NetCDF file with a formatted filename for wind data\n",
    "    output_file_path_wind = output_loc + f'sliced_OC-CCI_CCMP_v3.0_wind_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc'\n",
    "    ds_wind_sliced.to_netcdf(output_file_path_wind)\n",
    "\n",
    "    # Close the original and sliced wind datasets\n",
    "    ds_wind.close()\n",
    "    ds_wind_sliced.close()\n",
    "\n",
    "    print(f'Sliced wind dataset saved to {output_file_path_wind}')\n",
    "\n",
    "    # Define the path to the sliced chlorophyll dataset file\n",
    "    chlorophyll_file = nc.Dataset(output_loc+f'sliced_OC-CCI_chlor_a_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Get the chlorophyll variable data\n",
    "    chlorophyll = chlorophyll_file.variables['OC-CCI_chlor_a'][:]\n",
    "\n",
    "    # Define the path to the wind speed and direction dataset file\n",
    "    wind_file = nc.Dataset(output_loc+f'sliced_OC-CCI_CCMP_v3.0_wind_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Get the wind speed and wind direction variable data\n",
    "    wind_speed = wind_file.variables['CCMP_w'][:]\n",
    "    wind_direction = wind_file.variables['CCMP_wind_dir'][:]\n",
    "    \n",
    "    # Open the non-heatwave dataset file\n",
    "    non_heatwave_dataset_file = nc.Dataset(file_nonheatwave)\n",
    "\n",
    "    # Open the mask file for the specified region\n",
    "    mask_file = nc.Dataset(output_loc+f'consecutive_monthly_mask_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Get the mask variable for the specified region\n",
    "    mask_region = mask_file.variables['consecutive_monthly_mask'][:]\n",
    "\n",
    "    # Apply the mask to the chlorophyll data\n",
    "    chlorophyll_masked_year = np.ma.masked_array(chlorophyll, np.logical_not(mask_region))\n",
    "\n",
    "    # Apply the mask to the wind speed and wind direction data\n",
    "    wind_speed_masked_year = np.ma.masked_array(wind_speed, np.logical_not(mask_region))\n",
    "    wind_direction_masked_year = np.ma.masked_array(wind_direction, np.logical_not(mask_region))\n",
    "\n",
    "    # Calculate median values with the mask for chlorophyll, wind speed, and wind direction\n",
    "    chlorophyll_median_region_year = np.ma.median(chlorophyll_masked_year, axis=(1, 2))\n",
    "    wind_speed_median_region_year = np.ma.median(wind_speed_masked_year, axis=(1, 2))\n",
    "    wind_direction_median_region_year = np.ma.median(wind_direction_masked_year, axis=(1, 2))\n",
    "\n",
    "    # Get indices where the mask values are equal to any of the specified cat values (e.g., heatwave period)\n",
    "    indices_heatwave_region_year = np.where(np.isin(mask_region, combined_cat_values))[0]\n",
    "\n",
    "    # Get indices where the mask values are not equal to any of the specified cat values (e.g., non-heatwave period)\n",
    "    indices_non_heatwave_region_year = np.where(~np.isin(mask_region, combined_cat_values))[0]\n",
    "\n",
    "    # Perform the Wilcoxon signed-rank tests for chlorophyll, wind speed, and wind direction\n",
    "    p_values_chlorophyll_region_year = []\n",
    "    p_values_wind_speed_region_year = []\n",
    "    p_values_wind_direction_region_year = []\n",
    "\n",
    "    median_diff_chlorophyll_region_year = []\n",
    "    median_diff_wind_speed_region_year = []\n",
    "    median_diff_wind_direction_region_year = []\n",
    "\n",
    "    std_dev_chlorophyll_region_year = []\n",
    "    std_dev_wind_speed_region_year = []\n",
    "    std_dev_wind_direction_region_year = []\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Randomly select indices for heatwave and non-heatwave periods\n",
    "        sample_indices_region_heatwave_year = np.random.choice(indices_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "        sample_indices_region_non_heatwave_year = np.random.choice(indices_non_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "\n",
    "        # Filter the data based on the sampled indices for chlorophyll, wind speed, and wind direction\n",
    "        sample_chlorophyll_median_region_heatwave_year = chlorophyll_median_region_year[sample_indices_region_heatwave_year]\n",
    "        sample_chlorophyll_median_region_non_heatwave_year = chlorophyll_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "        sample_wind_speed_median_region_heatwave_year = wind_speed_median_region_year[sample_indices_region_heatwave_year]\n",
    "        sample_wind_speed_median_region_non_heatwave_year = wind_speed_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "        sample_wind_direction_median_region_heatwave_year = wind_direction_median_region_year[sample_indices_region_heatwave_year]\n",
    "        sample_wind_direction_median_region_non_heatwave_year = wind_direction_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "        # Perform the Wilcoxon signed-rank tests for chlorophyll\n",
    "        _, p_value_chlorophyll_region_year = wilcoxon(sample_chlorophyll_median_region_heatwave_year, sample_chlorophyll_median_region_non_heatwave_year)\n",
    "\n",
    "        # Perform the Wilcoxon signed-rank tests for wind speed\n",
    "        _, p_value_wind_speed_region_year = wilcoxon(sample_wind_speed_median_region_heatwave_year, sample_wind_speed_median_region_non_heatwave_year)\n",
    "\n",
    "        # Perform the Wilcoxon signed-rank tests for wind direction\n",
    "        _, p_value_wind_direction_region_year = wilcoxon(sample_wind_direction_median_region_heatwave_year, sample_wind_direction_median_region_non_heatwave_year)\n",
    "\n",
    "        # Append the p-values to the respective lists for all variables\n",
    "        p_values_chlorophyll_region_year.append(p_value_chlorophyll_region_year)\n",
    "        p_values_wind_speed_region_year.append(p_value_wind_speed_region_year)\n",
    "        p_values_wind_direction_region_year.append(p_value_wind_direction_region_year)\n",
    "\n",
    "        # Calculate the median difference and standard deviation for all variables\n",
    "        median_diff_chlorophyll_region_year.append(np.median(sample_chlorophyll_median_region_heatwave_year - sample_chlorophyll_median_region_non_heatwave_year))\n",
    "        median_diff_wind_speed_region_year.append(np.median(sample_wind_speed_median_region_heatwave_year - sample_wind_speed_median_region_non_heatwave_year))\n",
    "        median_diff_wind_direction_region_year.append(np.median(sample_wind_direction_median_region_heatwave_year - sample_wind_direction_median_region_non_heatwave_year))\n",
    "\n",
    "        std_dev_chlorophyll_region_year.append(np.std(sample_chlorophyll_median_region_heatwave_year - sample_chlorophyll_median_region_non_heatwave_year))\n",
    "        std_dev_wind_speed_region_year.append(np.std(sample_wind_speed_median_region_heatwave_year - sample_wind_speed_median_region_non_heatwave_year))\n",
    "        std_dev_wind_direction_region_year.append(np.std(sample_wind_direction_median_region_heatwave_year - sample_wind_direction_median_region_non_heatwave_year))\n",
    "\n",
    "    # Calculate the median p-values, median median differences, and median standard deviations for all variables\n",
    "    median_p_value_chlorophyll_region_year = np.median(p_values_chlorophyll_region_year)\n",
    "    median_p_value_wind_speed_region_year = np.median(p_values_wind_speed_region_year)\n",
    "    median_p_value_wind_direction_region_year = np.median(p_values_wind_direction_region_year)\n",
    "\n",
    "    median_median_diff_chlorophyll_region_year = np.median(median_diff_chlorophyll_region_year)\n",
    "    median_median_diff_wind_speed_region_year = np.median(median_diff_wind_speed_region_year)\n",
    "    median_median_diff_wind_direction_region_year = np.median(median_diff_wind_direction_region_year)\n",
    "\n",
    "    median_std_dev_chlorophyll_region_year = np.median(std_dev_chlorophyll_region_year)\n",
    "    median_std_dev_wind_speed_region_year = np.median(std_dev_wind_speed_region_year)\n",
    "    median_std_dev_wind_direction_region_year = np.median(std_dev_wind_direction_region_year)\n",
    "\n",
    "    # Calculate the coefficient of variation for all variables\n",
    "    cv_chlorophyll_region_year = median_std_dev_chlorophyll_region_year / np.median(chlorophyll_median_region_year)\n",
    "    cv_wind_speed_region_year = median_std_dev_wind_speed_region_year / np.median(wind_speed_median_region_year)\n",
    "    cv_wind_direction_region_year = median_std_dev_wind_direction_region_year / np.median(wind_direction_median_region_year)\n",
    "\n",
    "    # Function to check if the median difference passes the filter\n",
    "    def apply_filter(median_diff, precision):\n",
    "        return median_diff >= precision\n",
    "\n",
    "    # Define the precision for chlorophyll\n",
    "    precision_chlorophyll = 0.01  # mg m^-3\n",
    "\n",
    "    # Apply the quality filter for chlorophyll-a\n",
    "    chlorophyll_quality_filter = 0.01  # Threshold for chlorophyll-a in mg m^-3\n",
    "    chlorophyll_filtered_indices = np.where(chlorophyll_median_region_year >= chlorophyll_quality_filter)[0]\n",
    "\n",
    "    # Filter chlorophyll data based on the quality filter\n",
    "    chlorophyll_median_region_year_filtered = chlorophyll_median_region_year[chlorophyll_filtered_indices]\n",
    "\n",
    "    # Apply filter for chlorophyll\n",
    "    print(f\"Results for chlorophyll in {region_name} for {start_year}/{end_year} for {months_after} months after a consecutive period of {consecutive_months_threshold} months:\")\n",
    "    print(\"Median p-value:\", median_p_value_chlorophyll_region_year)\n",
    "    print(\"Median median difference:\", median_median_diff_chlorophyll_region_year)\n",
    "    print(\"Median standard deviation:\", median_std_dev_chlorophyll_region_year)\n",
    "\n",
    "    # Print the results for wind speed\n",
    "    print(f\"Results for wind speed in {region_name} for {start_year}/{end_year} for {months_after} months after a consecutive period of {consecutive_months_threshold} months:\")\n",
    "    print(\"Median p-value:\", median_p_value_wind_speed_region_year)\n",
    "    print(\"Median median difference:\", median_median_diff_wind_speed_region_year)\n",
    "    print(\"Median standard deviation:\", median_std_dev_wind_speed_region_year)\n",
    "\n",
    "    # Print the results for wind direction\n",
    "    print(f\"Results for wind direction in {region_name} for {start_year}/{end_year} for {months_after} months after a consecutive period of {consecutive_months_threshold} months:\")\n",
    "    print(\"Median p-value:\", median_p_value_wind_direction_region_year)\n",
    "    print(\"Median median difference:\", median_median_diff_wind_direction_region_year)\n",
    "    print(\"Median standard deviation:\", median_std_dev_wind_direction_region_year)\n",
    "\n",
    "    # Extract combined category values from the first row of the 'combined_cat_values' column\n",
    "    combined_cat_values = parameters_df['combined_cat_values'].iloc[0]\n",
    "\n",
    "    # Extract the numbers from the combined_cat_values string\n",
    "    numbers = ''.join(filter(str.isdigit, combined_cat_values))\n",
    "\n",
    "    # Insert an underscore between the numbers\n",
    "    formatted_numbers = '_'.join(numbers)\n",
    "\n",
    "    # Construct the filename\n",
    "    csv_filename = output_loc+f\"results_cat_{formatted_numbers}.csv\"\n",
    "\n",
    "    # Check if the file exists, if not, create it and write the header\n",
    "    if not os.path.exists(csv_filename):\n",
    "        with open(csv_filename, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            # Write header\n",
    "            csv_writer.writerow([\"Region Name\", \"Start Year\", \"End Year\", \"months_after\", \"Consecutive Months Threshold\", \"combined_cat_values\", \"Parameter\", \"Median p-value\", \"Median median difference\", \"Median standard deviation\", \"Significance\", \"HW Start Date\", \"HW End Date\"])\n",
    "\n",
    "    # Append data to CSV\n",
    "    with open(csv_filename, 'a', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        # Write data rows\n",
    "        csv_writer.writerows(results)\n",
    "\n",
    "        print(\"Results in\", region_name, \"appended to\", csv_filename)\n",
    "    # Check if the file exists, if not, create it and write the header\n",
    "    if not os.path.exists(csv_filename):\n",
    "        with open(csv_filename, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            # Write header\n",
    "            csv_writer.writerow([\"Region Name\", \"Start Year\", \"End Year\", \"Months After\", \"Consecutive Months Threshold\", \"combined_cat_values\", \"Parameter\", \"Median p-value\", \"Median median difference\", \"Median standard deviation\", \"Significance\", \"HW Start Date\", \"HW End Date\"])\n",
    "    \n",
    "    # Define significance level\n",
    "    significance_level = 0.01\n",
    "\n",
    "    # Define a function to determine significance\n",
    "    def determine_significance(p_value):\n",
    "        return \"Significant\" if p_value <= significance_level else \"Non-Significant\"\n",
    "\n",
    "    # Determine significance for each parameter\n",
    "    significance_chlorophyll = determine_significance(median_p_value_chlorophyll_region_year)\n",
    "    significance_wind_speed = determine_significance(median_p_value_wind_speed_region_year)\n",
    "    significance_wind_direction = determine_significance(median_p_value_wind_direction_region_year)\n",
    "\n",
    "    # Define the data to be written to the CSV\n",
    "    data = [\n",
    "        [region_name, start_year, end_year, months_after, consecutive_months_threshold, combined_cat_values, \"Chlorophyll\", median_p_value_chlorophyll_region_year, median_median_diff_chlorophyll_region_year, median_std_dev_chlorophyll_region_year, significance_chlorophyll, hw_first_date, hw_last_date],\n",
    "        [region_name, start_year, end_year, months_after, consecutive_months_threshold, combined_cat_values, \"Wind Speed\", median_p_value_wind_speed_region_year, median_median_diff_wind_speed_region_year, median_std_dev_wind_speed_region_year, significance_wind_speed, hw_first_date, hw_last_date],\n",
    "        [region_name, start_year, end_year, months_after, consecutive_months_threshold, combined_cat_values, \"Wind Direction\", median_p_value_wind_direction_region_year, median_median_diff_wind_direction_region_year, median_std_dev_wind_direction_region_year, significance_wind_direction, hw_first_date, hw_last_date]\n",
    "    ]\n",
    "\n",
    "    # Append data to CSV\n",
    "    with open(csv_filename, 'a', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        # Write data rows\n",
    "        csv_writer.writerows(data)\n",
    "\n",
    "    print(\"Results appended to\", csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b7e905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

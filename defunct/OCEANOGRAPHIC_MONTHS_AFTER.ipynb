{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d5222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\df391\\AppData\\Local\\Temp\\ipykernel_28568\\1749870198.py:436: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(start='1982-01-01', end='2022-12-31', freq='M')  # Assuming 1982-01-01 is the start of your dataset\n",
      "C:\\Users\\df391\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\numpy\\core\\fromnumeric.py:771: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  a.partition(kth, axis=axis, kind=kind, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fgco2 in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for ph_total in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for omega_ar in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for temperature in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for spco2 in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for talk in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\df391\\AppData\\Local\\Temp\\ipykernel_28568\\1749870198.py:436: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(start='1982-01-01', end='2022-12-31', freq='M')  # Assuming 1982-01-01 is the start of your dataset\n",
      "C:\\Users\\df391\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\numpy\\core\\fromnumeric.py:771: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  a.partition(kth, axis=axis, kind=kind, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fgco2 in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for ph_total in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for omega_ar in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for temperature in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for spco2 in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for talk in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\df391\\AppData\\Local\\Temp\\ipykernel_28568\\1749870198.py:436: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(start='1982-01-01', end='2022-12-31', freq='M')  # Assuming 1982-01-01 is the start of your dataset\n",
      "C:\\Users\\df391\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\numpy\\core\\fromnumeric.py:771: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  a.partition(kth, axis=axis, kind=kind, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fgco2 in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for ph_total in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for omega_ar in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for temperature in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for spco2 in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for talk in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\df391\\AppData\\Local\\Temp\\ipykernel_28568\\1749870198.py:436: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(start='1982-01-01', end='2022-12-31', freq='M')  # Assuming 1982-01-01 is the start of your dataset\n",
      "C:\\Users\\df391\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\numpy\\core\\fromnumeric.py:771: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  a.partition(kth, axis=axis, kind=kind, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fgco2 in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for ph_total in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for omega_ar in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for temperature in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for spco2 in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for talk in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\df391\\AppData\\Local\\Temp\\ipykernel_28568\\1749870198.py:436: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(start='1982-01-01', end='2022-12-31', freq='M')  # Assuming 1982-01-01 is the start of your dataset\n",
      "C:\\Users\\df391\\Anaconda3\\envs\\OceanHealth\\lib\\site-packages\\numpy\\core\\fromnumeric.py:771: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  a.partition(kth, axis=axis, kind=kind, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fgco2 in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for ph_total in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for omega_ar in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for temperature in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for spco2 in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n",
      "Results for talk in ANTA appended to D:/OceanHealth/output/results_cat_3_4.csv\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "#from docx import Document\n",
    "import os\n",
    "import csv\n",
    "   \n",
    "\n",
    "# Read parameter combinations from CSV file\n",
    "csv_file_path = \"C:/Users/df391/OneDrive - University of Exeter/Post_Doc_Ocean_Health/HeatwaveAnalysis/PARAMETERS.csv\"  # Replace with the actual path\n",
    "heatwave_file = \"D:/OceanHealth/GlobalAtlas_MHW_ESACCISST_1deg_1982-2021.nc\"\n",
    "longhurst_file = 'D:/OceanHealth/Longhurst_1_deg.nc'\n",
    "oceansoda_file = 'D:/Data/_DataSets/OCEANSODA_CO2/OceanSODA_ETHZ-v2023.OCADS.01_1982-2022.nc'\n",
    "#oceansoda_climatology_file = 'D:/OceanHealth/all_variables_monthly_avg_overall.nc'\n",
    "output_loc = 'D:/OceanHealth/output/'\n",
    "parameters_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Remove extra spaces from column names\n",
    "parameters_df.columns = parameters_df.columns.str.strip()\n",
    "\n",
    "for index, row in parameters_df.iterrows():\n",
    "    start_year = row['start_year']\n",
    "    oceansoda_climatology_file = 'D:/OceanHealth/all_variables_monthly_avg_'+str(start_year)+'.nc'\n",
    "    end_year = row['end_year']\n",
    "    longhurst_region_code = row['longhurst_region_code']\n",
    "    region_name = row['region_name']\n",
    "    combined_cat_values = [3, 4]\n",
    "    num_samples = row['num_samples']\n",
    "    consecutive_months_threshold = row['consecutive_months_threshold']\n",
    "    months_after = row['months_after']  \n",
    "\n",
    "    # Section 1: Load and Preprocess Data\n",
    "    # Load the netCDF file containing variables other than chlorophyll\n",
    "    dataset = xr.open_dataset(heatwave_file, decode_times=False,autoclose=True)\n",
    "\n",
    "    # Define the start and end indices for slicing\n",
    "    start_idx = (start_year - 1982) * 365\n",
    "    end_idx = start_idx + (end_year - start_year + 1) * 365 - 1\n",
    "\n",
    "    # Create a new dataset with data only for the specified time range\n",
    "    new_dataset = dataset.isel(time=slice(start_idx, end_idx + 1))\n",
    "\n",
    "    # Convert data variables to float32 if needed\n",
    "    new_dataset['cat'] = new_dataset['cat'].astype('float32')\n",
    "    new_dataset['mhw'] = new_dataset['mhw'].astype('float32')\n",
    "\n",
    "    # Save the new dataset to a new netCDF file\n",
    "    new_dataset.to_netcdf(output_loc+f'{region_name}{consecutive_months_threshold}_{months_after}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Section 2: Mask Based on Longhurst Regions\n",
    "    # Open the Longhurst region file\n",
    "    longhurst_dataset = xr.open_dataset(longhurst_file,autoclose=True)\n",
    "\n",
    "    # Read the Longhurst variable\n",
    "    longhurst = longhurst_dataset['longhurst'].values\n",
    "\n",
    "    # Create a mask based on Longhurst regions and transpose it\n",
    "    mask = np.isin(longhurst, [longhurst_region_code]).T\n",
    "\n",
    "    # Apply the mask to the entire time range\n",
    "    masked_dataset = new_dataset.where(mask)\n",
    "\n",
    "    # Save the masked data to a new netCDF file\n",
    "    masked_file_path = output_loc+f'masked_{region_name}{consecutive_months_threshold}_{months_after}_{start_year}_{end_year}.nc'\n",
    "    masked_dataset.to_netcdf(masked_file_path)\n",
    "\n",
    "    # Section 3: Create Monthly Masks with Values Only Inside Longhurst Region\n",
    "    # Load the netCDF file containing the masked data\n",
    "    masked_nc_file = xr.open_dataset(masked_file_path, decode_times=False, autoclose=True)\n",
    "\n",
    "    # Extract the masked cat variable and apply the Longhurst mask\n",
    "    masked_cat = masked_nc_file['cat'].where(mask)\n",
    "\n",
    "    # Calculate the number of months\n",
    "    num_months = int(len(masked_nc_file['time']) / 30)\n",
    "\n",
    "    # Create an empty array to store monthly masks\n",
    "    monthly_masks = np.zeros((num_months, len(masked_nc_file['lat']), len(masked_nc_file['lon']))) * np.nan\n",
    "\n",
    "    # Iterate over each month\n",
    "    for month in range(num_months):\n",
    "        # Calculate the start and end indices for the current month\n",
    "        start_idx = month * 30\n",
    "        end_idx = (month + 1) * 30\n",
    "\n",
    "        # Extract the masked daily cat values for the current month\n",
    "        month_data = masked_cat[start_idx:end_idx]\n",
    "\n",
    "        # Find the maximum category occurrence for each lat-lon point in the current month\n",
    "        max_values = np.max(month_data, axis=0)\n",
    "\n",
    "        # Set areas impacted by the highest category occurrence within the Longhurst region\n",
    "        monthly_mask = np.where(mask, max_values, np.nan)\n",
    "\n",
    "        # Save the monthly mask\n",
    "        monthly_masks[month] = monthly_mask\n",
    "\n",
    "    # Create a new netCDF file to save the monthly masks\n",
    "    output_file = xr.Dataset(\n",
    "        data_vars={\n",
    "            'lat': ('lat', masked_nc_file['lat'].values),\n",
    "            'lon': ('lon', masked_nc_file['lon'].values),\n",
    "            'time': ('time', np.arange(1, num_months + 1)),\n",
    "            'monthly_masks': (['time', 'lat', 'lon'], monthly_masks)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add attributes\n",
    "    output_file['lat'].attrs['units'] = 'degrees_north'\n",
    "    output_file['lon'].attrs['units'] = 'degrees_east'\n",
    "    output_file['time'].attrs['units'] = f'months since {start_year}-01-01'\n",
    "    output_file['monthly_masks'].attrs['units'] = '1'\n",
    "    output_file.attrs['description'] = f'Monthly masks for marine heatwaves in {region_name}'\n",
    "\n",
    "    # Save the monthly masks to a new netCDF file\n",
    "    output_file.to_netcdf(output_loc+f'monthly_masks_{region_name}{consecutive_months_threshold}_{months_after}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Close the netCDF files\n",
    "    masked_nc_file.close()\n",
    "\n",
    "    # Section 4: Create Consecutive Monthly Mask for Values 3 or 4\n",
    "    # Load the netCDF file containing the monthly masks\n",
    "    monthly_masks_file = xr.open_dataset(output_loc+f'monthly_masks_{region_name}{consecutive_months_threshold}_{months_after}_{start_year}_{end_year}.nc', decode_times=False, autoclose=True)\n",
    "\n",
    "    # Extract the monthly masks variable\n",
    "    monthly_masks_data = monthly_masks_file['monthly_masks'].values\n",
    "\n",
    "    # Initialize the consecutive monthly mask array\n",
    "    consecutive_monthly_mask = np.zeros_like(monthly_masks) * np.nan\n",
    "\n",
    "    # Iterate over each lat-lon point\n",
    "    for lat_idx in range(monthly_masks_data.shape[1]):\n",
    "        for lon_idx in range(monthly_masks_data.shape[2]):\n",
    "            # Extract the monthly mask values for the current lat-lon point\n",
    "            values = monthly_masks_data[:, lat_idx, lon_idx]\n",
    "\n",
    "            consecutive_count = 0\n",
    "            consecutive_mask = np.zeros_like(values)\n",
    "\n",
    "            for i in range(len(values)):\n",
    "                if (values[i] == 3) or (values[i] == 4):\n",
    "                    consecutive_count += 1\n",
    "                    consecutive_mask[i] = values[i]\n",
    "                else:\n",
    "                    consecutive_count = 0\n",
    "                    consecutive_mask[i] = 0\n",
    "\n",
    "                if consecutive_count >= consecutive_months_threshold:\n",
    "                    break\n",
    "\n",
    "            # Set the consecutive monthly mask values for the current lat-lon point\n",
    "            consecutive_monthly_mask[:len(consecutive_mask), lat_idx, lon_idx] = consecutive_mask\n",
    "\n",
    "    # Apply the Longhurst mask to set values inside the region to NaN\n",
    "    consecutive_monthly_mask = np.where(mask, consecutive_monthly_mask, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "    # Create a new netCDF file to save the consecutive monthly mask\n",
    "    consecutive_monthly_mask_file = xr.Dataset(\n",
    "        data_vars={\n",
    "            'lat': ('lat', monthly_masks_file['lat'].values),\n",
    "            'lon': ('lon', monthly_masks_file['lon'].values),\n",
    "            'time': ('time', monthly_masks_file['time'].values),\n",
    "            'consecutive_monthly_mask': (['time', 'lat', 'lon'], consecutive_monthly_mask)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add attributes\n",
    "    consecutive_monthly_mask_file['lat'].attrs['units'] = 'degrees_north'\n",
    "    consecutive_monthly_mask_file['lon'].attrs['units'] = 'degrees_east'\n",
    "    consecutive_monthly_mask_file['time'].attrs['units'] = f'months since {start_year}-01-01'\n",
    "    consecutive_monthly_mask_file['consecutive_monthly_mask'].attrs['units'] = '1'\n",
    "    consecutive_monthly_mask_file.attrs['description'] = f'Consecutive monthly mask for values 3 or 4 in {region_name}'\n",
    "\n",
    "    # Save the consecutive monthly mask to a new netCDF file\n",
    "    consecutive_monthly_mask_file.to_netcdf(output_loc+f'consecutive_monthly_mask_{region_name}{consecutive_months_threshold}_{months_after}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Close the netCDF files\n",
    "    monthly_masks_file.close()\n",
    "    consecutive_monthly_mask_file.close()\n",
    "\n",
    "    # Initialize a list to store information about consecutive heatwaves\n",
    "    consecutive_heatwave_info = []\n",
    "\n",
    "    # Iterate over each lat-lon point\n",
    "    for lat_idx in range(consecutive_monthly_mask.shape[1]):\n",
    "        for lon_idx in range(consecutive_monthly_mask.shape[2]):\n",
    "            # Extract the consecutive monthly mask values for the current lat-lon point\n",
    "            values = consecutive_monthly_mask[:, lat_idx, lon_idx]\n",
    "\n",
    "            # Find indices where consecutive heatwaves occurred (values 3 or 4)\n",
    "            heatwave_indices = np.where(np.isin(values, [3, 4]))[0]\n",
    "\n",
    "            # If consecutive heatwaves occurred at this lat-lon point\n",
    "            if len(heatwave_indices) >= consecutive_months_threshold:\n",
    "                # Get the corresponding dates for the identified indices\n",
    "                heatwave_dates = monthly_masks_file['time'].values[heatwave_indices]\n",
    "\n",
    "                # Convert months to dates based on the start_year\n",
    "                start_date = pd.to_datetime(f'{start_year}-01-01')\n",
    "                exact_dates = [(start_date + pd.DateOffset(months=int(month))).strftime('%Y-%m-%d') for month in heatwave_dates]\n",
    "\n",
    "                # Append the lat, lon, months, and exact_dates to the list\n",
    "                consecutive_heatwave_info.append({\n",
    "                    'lat': monthly_masks_file['lat'].values[lat_idx],\n",
    "                    'lon': monthly_masks_file['lon'].values[lon_idx],\n",
    "                    'months': heatwave_dates.tolist(),\n",
    "                    'exact_dates': exact_dates\n",
    "                })\n",
    "\n",
    "    # Create a DataFrame with the extracted information\n",
    "    consecutive_heatwave_info_df = pd.DataFrame(consecutive_heatwave_info)\n",
    "\n",
    "    # Save the DataFrame to a CSV file with region name, start year, and end year in the filename\n",
    "    csv_file_path = output_loc+f'consecutive_heatwave_info_{region_name}{consecutive_months_threshold}_{months_after}_{start_year}_{end_year}.csv'\n",
    "    consecutive_heatwave_info_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "\n",
    "    # Section 4: Create Consecutive Monthly Mask for Values 3 or 4\n",
    "    # Load the netCDF file containing the monthly masks\n",
    "    monthly_masks_file = xr.open_dataset(output_loc+f'monthly_masks_{region_name}{consecutive_months_threshold}_{months_after}_{start_year}_{end_year}.nc', decode_times=False, autoclose=True)\n",
    "\n",
    "    # Extract the monthly masks variable\n",
    "    monthly_masks_data = monthly_masks_file['monthly_masks'].values\n",
    "\n",
    "    # Initialize the consecutive monthly mask array\n",
    "    consecutive_monthly_mask = np.zeros_like(monthly_masks) * np.nan\n",
    "\n",
    "    # Iterate over each lat-lon point\n",
    "    for lat_idx in range(monthly_masks_data.shape[1]):\n",
    "        for lon_idx in range(monthly_masks_data.shape[2]):\n",
    "            # Extract the monthly mask values for the current lat-lon point\n",
    "            values = monthly_masks_data[:, lat_idx, lon_idx]\n",
    "\n",
    "            consecutive_count = 0\n",
    "            consecutive_mask = np.zeros_like(values)\n",
    "\n",
    "            for i in range(len(values)):\n",
    "                if (values[i] == 3) or (values[i] == 4):\n",
    "                    consecutive_count += 1\n",
    "                    consecutive_mask[i] = values[i]\n",
    "                else:\n",
    "                    consecutive_count = 0\n",
    "                    consecutive_mask[i] = 0\n",
    "\n",
    "                if consecutive_count >= consecutive_months_threshold:\n",
    "                    break\n",
    "\n",
    "            # Set the consecutive monthly mask values for the current lat-lon point\n",
    "            consecutive_monthly_mask[:len(consecutive_mask), lat_idx, lon_idx] = consecutive_mask\n",
    "\n",
    "    # Apply the Longhurst mask to set values inside the region to NaN\n",
    "    consecutive_monthly_mask = np.where(mask, consecutive_monthly_mask, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "    # Create a new netCDF file to save the consecutive monthly mask\n",
    "    consecutive_monthly_mask_file = xr.Dataset(\n",
    "        data_vars={\n",
    "            'lat': ('lat', monthly_masks_file['lat'].values),\n",
    "            'lon': ('lon', monthly_masks_file['lon'].values),\n",
    "            'time': ('time', monthly_masks_file['time'].values),\n",
    "            'consecutive_monthly_mask': (['time', 'lat', 'lon'], consecutive_monthly_mask)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add attributes\n",
    "    consecutive_monthly_mask_file['lat'].attrs['units'] = 'degrees_north'\n",
    "    consecutive_monthly_mask_file['lon'].attrs['units'] = 'degrees_east'\n",
    "    consecutive_monthly_mask_file['time'].attrs['units'] = f'months since {start_year}-01-01'\n",
    "    consecutive_monthly_mask_file['consecutive_monthly_mask'].attrs['units'] = '1'\n",
    "    consecutive_monthly_mask_file.attrs['description'] = f'Consecutive monthly mask for values 3 or 4 in {region_name}'\n",
    "\n",
    "    # Save the consecutive monthly mask to a new netCDF file\n",
    "    consecutive_monthly_mask_file.to_netcdf(output_loc+f'consecutive_monthly_mask_{region_name}{consecutive_months_threshold}_{months_after}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Close the netCDF files\n",
    "    monthly_masks_file.close()\n",
    "    consecutive_monthly_mask_file.close()\n",
    "\n",
    "    # Initialize a list to store information about consecutive heatwaves\n",
    "    consecutive_heatwave_info = []\n",
    "\n",
    "    # Iterate over each lat-lon point\n",
    "    for lat_idx in range(consecutive_monthly_mask.shape[1]):\n",
    "        for lon_idx in range(consecutive_monthly_mask.shape[2]):\n",
    "            # Extract the consecutive monthly mask values for the current lat-lon point\n",
    "            values = consecutive_monthly_mask[:, lat_idx, lon_idx]\n",
    "\n",
    "            # Find indices where consecutive heatwaves occurred (values 3 or 4)\n",
    "            heatwave_indices = np.where(np.isin(values, [3, 4]))[0]\n",
    "\n",
    "            # If consecutive heatwaves occurred at this lat-lon point\n",
    "            if len(heatwave_indices) >= consecutive_months_threshold:\n",
    "                # Get the corresponding dates for the identified indices\n",
    "                heatwave_dates = monthly_masks_file['time'].values[heatwave_indices]\n",
    "\n",
    "                # Convert months to dates based on the start_year\n",
    "                start_date = pd.to_datetime(f'{start_year}-01-01')\n",
    "                exact_dates = [(start_date + pd.DateOffset(months=int(month))).strftime('%Y-%m-%d') for month in heatwave_dates]\n",
    "\n",
    "                # Append the lat, lon, months, and exact_dates to the list\n",
    "                consecutive_heatwave_info.append({\n",
    "                    'lat': monthly_masks_file['lat'].values[lat_idx],\n",
    "                    'lon': monthly_masks_file['lon'].values[lon_idx],\n",
    "                    'months': heatwave_dates.tolist(),\n",
    "                    'exact_dates': exact_dates\n",
    "                })\n",
    "\n",
    "    # Create a DataFrame with the extracted information\n",
    "    consecutive_heatwave_info_df = pd.DataFrame(consecutive_heatwave_info)\n",
    "\n",
    "    # Save the DataFrame to a CSV file with region name, start year, and end year in the filename\n",
    "    csv_file_path = output_loc+f'consecutive_heatwave_info_{region_name}{consecutive_months_threshold}_{months_after}_{start_year}_{end_year}.csv'\n",
    "    consecutive_heatwave_info_df.to_csv(csv_file_path, index=False)\n",
    "   \n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "    import pandas as pd\n",
    "    import xarray as xr\n",
    "    import numpy as np\n",
    "\n",
    "    # Function to calculate date after 'n' months with day set to 1\n",
    "    def calculate_date_after_n_months(start_date, n):\n",
    "        # Calculate the date after 'n' months\n",
    "        result_date = start_date + timedelta(days=30 * n)\n",
    "        # Set the day to 1\n",
    "        result_date = result_date.replace(day=1)\n",
    "        # Format the date as 'YYYY-MM-DD'\n",
    "        return result_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Load the consecutive heatwave information CSV file\n",
    "    csv_file_path = output_loc+f'consecutive_heatwave_info_{region_name}{consecutive_months_threshold}_{months_after}_{start_year}_{end_year}.csv'\n",
    "    consecutive_heatwave_info_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Convert 'exact_dates' column to list of lists of datetime objects\n",
    "    consecutive_heatwave_info_df['exact_dates'] = consecutive_heatwave_info_df['exact_dates'].apply(eval).apply(lambda x: [datetime.strptime(date_str, '%Y-%m-%d') for date_str in x])\n",
    "\n",
    "    # Function to calculate date after 'n' months for each heatwave event\n",
    "    def calculate_date_after_n_months_list(dates_list, n):\n",
    "        return [calculate_date_after_n_months(date, n) for date in dates_list]\n",
    "\n",
    "    # Apply the function to calculate the date after 'n' months for each heatwave event\n",
    "    consecutive_heatwave_info_df[f'date_after_{months_after}_months'] = consecutive_heatwave_info_df['exact_dates'].apply(lambda x: calculate_date_after_n_months_list(x, months_after))\n",
    "\n",
    "    # Define the end date for masking ('n' months after start date)\n",
    "    end_date = datetime.strptime('2022-12-31', '%Y-%m-%d')\n",
    "\n",
    "    # Create a mask for dates after 'n' months from start date\n",
    "    mask = consecutive_heatwave_info_df[f'date_after_{months_after}_months'].apply(lambda x: all(datetime.strptime(date, '%Y-%m-%d') <= end_date for date in x))\n",
    "\n",
    "    # Apply the mask\n",
    "    masked_heatwaves = consecutive_heatwave_info_df[mask]\n",
    "\n",
    "    # Convert the strings representing lists to actual lists of integers in the 'months' column\n",
    "    masked_heatwaves['months'] = masked_heatwaves['months'].apply(eval)\n",
    "\n",
    "    # Add 'n' to each value in the 'months' column to get the new months for 'date_after_n_months'\n",
    "    masked_heatwaves[f'months_date_after_{months_after}_months'] = masked_heatwaves['months'].apply(lambda x: [month + months_after for month in x])\n",
    "\n",
    "    # Define the output file name with the current date\n",
    "    output_file_name = output_loc+f\"masked_consecutive_heatwave_info_{region_name}{consecutive_months_threshold}_{months_after}_{start_year}_{end_year}.csv\"\n",
    "\n",
    "    # Save the masked DataFrame to a CSV file\n",
    "    masked_heatwaves.to_csv(output_file_name, index=False)\n",
    "\n",
    "    # Load the netCDF file containing the monthly masks\n",
    "    monthly_masks_file = xr.open_dataset(output_loc+f'monthly_masks_{region_name}{consecutive_months_threshold}_{months_after}_{start_year}_{end_year}.nc', decode_times=False)\n",
    "\n",
    "    # Extract the third month values from the 'months_date_after_n_months' column\n",
    "    third_month_values = masked_heatwaves[f'months_date_after_{months_after}_months'].apply(lambda x: int(x[2]))\n",
    "\n",
    "    # Extract latitudes and longitudes\n",
    "    lats = masked_heatwaves['lat'].values\n",
    "    lons = masked_heatwaves['lon'].values\n",
    "\n",
    "    # Initialize a mask array\n",
    "    mask_array = np.zeros_like(monthly_masks_file['monthly_masks'].values)\n",
    "\n",
    "    for i, (lat, lon, month_value) in enumerate(zip(lats, lons, third_month_values)):\n",
    "        # Find the indices corresponding to the given latitude and longitude\n",
    "        lat_index = np.where(monthly_masks_file['lat'].values == lat)[0]\n",
    "        lon_index = np.where(monthly_masks_file['lon'].values == lon)[0]\n",
    "\n",
    "        # Check if the index is within bounds\n",
    "        if month_value - 1 < mask_array.shape[0] and lat_index.size > 0 and lon_index.size > 0:\n",
    "            # Set the value of the third month at the corresponding lat-lon position\n",
    "            mask_array[month_value - 1, lat_index[0], lon_index[0]] = monthly_masks_file['monthly_masks'].values[month_value - 1, lat_index[0], lon_index[0]]\n",
    "\n",
    "    # Set NaN values back to NaN\n",
    "    mask_array[np.isnan(monthly_masks_file['monthly_masks'].values)] = np.nan\n",
    "    \n",
    "    # Create a new xarray dataset with the extracted mask\n",
    "    mask_dataset = xr.Dataset(\n",
    "        data_vars={\n",
    "            'lat': ('lat', monthly_masks_file['lat'].values),\n",
    "            'lon': ('lon', monthly_masks_file['lon'].values),\n",
    "            'time': ('time', monthly_masks_file['time'].values),\n",
    "            'masked_values': (['time', 'lat', 'lon'], mask_array)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add attributes\n",
    "    mask_dataset['lat'].attrs['units'] = 'degrees_north'\n",
    "    mask_dataset['lon'].attrs['units'] = 'degrees_east'\n",
    "    mask_dataset['time'].attrs['units'] = 'months since 2014-01-01'\n",
    "    mask_dataset['masked_values'].attrs['units'] = '1'\n",
    "    mask_dataset.attrs['description'] = 'Masked values for specific latitudes, longitudes, and months'\n",
    "\n",
    "    # Save the masked values to a new netCDF file\n",
    "    mask_dataset.to_netcdf(output_loc+f'masked_values_consecutive_heatwave_info_{region_name}{consecutive_months_threshold}_{months_after}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Close the netCDF file\n",
    "    monthly_masks_file.close()\n",
    "    \n",
    "\n",
    "    # Section 4: Statistical Analysis\n",
    "    # Open the heatwave dataset file\n",
    "    heatwave_dataset_file = nc.Dataset(oceansoda_file)\n",
    "\n",
    "    # Open the non-heatwave dataset file\n",
    "    non_heatwave_dataset_file = nc.Dataset(oceansoda_climatology_file)\n",
    "\n",
    "    # Get the variable data for heatwave dataset\n",
    "    variables_heatwave = ['fgco2', 'ph_total', 'omega_ar', 'temperature', 'spco2', 'talk']\n",
    "    heatwave_data = {var: heatwave_dataset_file.variables[var][:] for var in variables_heatwave}\n",
    "\n",
    "    # Get the variable data for non-heatwave dataset\n",
    "    variables_non_heatwave = ['fgco2', 'ph_total', 'omega_ar', 'temperature', 'spco2', 'talk']\n",
    "    non_heatwave_data = {var: non_heatwave_dataset_file.variables[var][:] for var in variables_non_heatwave}\n",
    "\n",
    "    # Create the time axis for the specified years\n",
    "    dates = pd.date_range(start='1982-01-01', end='2022-12-31', freq='M')  # Assuming 1982-01-01 is the start of your dataset\n",
    "\n",
    "    # Find the indices corresponding to the time period\n",
    "    start_index = (start_year - 1982) * 12\n",
    "    end_index = start_index + (end_year - start_year + 1) * 12\n",
    "\n",
    "    # Slice the data for the specified years in heatwave dataset\n",
    "    heatwave_data_year = {var: data[start_index:end_index] for var, data in heatwave_data.items()}\n",
    "\n",
    "    # Slice the data for the non-heatwave dataset for the corresponding months\n",
    "    non_heatwave_data_year = {var: data[:12] for var, data in non_heatwave_data.items()}\n",
    "\n",
    "    # Open the mask file for the specified region\n",
    "    mask_file = nc.Dataset(output_loc+f'masked_values_consecutive_heatwave_info_{region_name}{consecutive_months_threshold}_{months_after}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Get the mask variable for the specified region\n",
    "    mask_region = mask_file.variables['masked_values'][:]\n",
    "\n",
    "    # Get indices where the mask values are equal to any of the specified cat values (e.g., heatwave period)\n",
    "    indices_heatwave_region_year = np.where(np.isin(mask_region, combined_cat_values))[0]\n",
    "\n",
    "    # Get indices where the mask values are not equal to any of the specified cat values (e.g., non-heatwave period)\n",
    "    indices_non_heatwave_region_year = np.where(~np.isin(mask_region, combined_cat_values))[0]\n",
    "\n",
    "    # Iterate over each variable for analysis\n",
    "    for variable in variables_heatwave:\n",
    "        # Initialize a list to store results for each variable\n",
    "        results = []\n",
    "\n",
    "        # Get the data for the variable\n",
    "        variable_heatwave = heatwave_data_year[variable]\n",
    "        variable_non_heatwave = non_heatwave_data_year[variable]\n",
    "\n",
    "        # Apply the mask to the sliced data in heatwave dataset\n",
    "        variable_masked_year = np.ma.masked_array(variable_heatwave, np.logical_not(mask_region))\n",
    "\n",
    "        # Calculate the cyclic index for mask_region to match the time dimension of non-heatwave data\n",
    "        cyclic_indices = np.arange(12) % 12  # Generate cyclic indices from 0 to 11\n",
    "\n",
    "        # Synchronize dimensions of mask_region with non-heatwave data using cyclic indices\n",
    "        mask_region_synced = mask_region[cyclic_indices]\n",
    "\n",
    "        # Mask the non-heatwave dataset variables with the synchronized mask\n",
    "        variable_non_heatwave_masked_year = np.ma.masked_array(variable_non_heatwave, np.logical_not(mask_region_synced))\n",
    "\n",
    "        # Calculate median values with the mask for the variable\n",
    "        variable_median_region_year = np.ma.median(variable_masked_year, axis=(1, 2))\n",
    "        variable_non_heatwave_median_region_year = np.ma.median(variable_non_heatwave_masked_year, axis=(1, 2))\n",
    "\n",
    "        # Perform the Wilcoxon signed-rank tests\n",
    "        p_values_region_year = []\n",
    "        median_diff_region_year = []\n",
    "        std_dev_region_year = []\n",
    "\n",
    "        for _ in range(num_samples):\n",
    "            # Randomly select indices for heatwave and non-heatwave periods\n",
    "            sample_indices_region_heatwave_year = np.random.choice(indices_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "            # Randomly select indices for non-heatwave periods, ensuring they are within the valid range (0-11)\n",
    "            sample_indices_region_non_heatwave_year = np.random.choice(range(12), len(indices_heatwave_region_year), replace=True)\n",
    "\n",
    "            # Adjust indices for non-heatwave year to ensure they are within the valid range (0-11)\n",
    "            sample_indices_region_non_heatwave_year = sample_indices_region_non_heatwave_year % 12\n",
    "\n",
    "            # Filter the data based on the sampled indices\n",
    "            sample_variable_median_region_heatwave_year = variable_median_region_year[sample_indices_region_heatwave_year]\n",
    "            sample_variable_median_region_non_heatwave_year = variable_non_heatwave_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "            # Perform the Wilcoxon signed-rank tests\n",
    "            _, p_value_region_year = wilcoxon(sample_variable_median_region_heatwave_year, sample_variable_median_region_non_heatwave_year)\n",
    "\n",
    "            # Calculate the median difference and standard deviation\n",
    "            median_diff_region_year.append(np.median(sample_variable_median_region_heatwave_year - sample_variable_median_region_non_heatwave_year))\n",
    "            std_dev_region_year.append(np.std(sample_variable_median_region_heatwave_year - sample_variable_median_region_non_heatwave_year))\n",
    "\n",
    "            # Append the p-value to the respective list\n",
    "            p_values_region_year.append(p_value_region_year)\n",
    "\n",
    "        # Calculate median p-value, median difference, and median standard deviation\n",
    "        median_p_value = np.median(p_values_region_year)\n",
    "        median_median_diff = np.median(median_diff_region_year)\n",
    "        median_std_dev = np.median(std_dev_region_year)\n",
    "\n",
    "        # Define the function to determine significance\n",
    "        def determine_significance(p_value):\n",
    "            if p_value < 0.01:\n",
    "                return \"Significant\"\n",
    "            else:\n",
    "                return \"Not Significant\"\n",
    "\n",
    "        # Determine significance\n",
    "        significance = determine_significance(median_p_value)\n",
    "\n",
    "        # Append results to the list\n",
    "        results.append([region_name, start_year, end_year,months_after, consecutive_months_threshold,  combined_cat_values, variable, median_p_value, median_median_diff, median_std_dev, significance])\n",
    "       \n",
    "        # Extract combined category values from the first row of the 'combined_cat_values' column\n",
    "        combined_cat_values = parameters_df['combined_cat_values'].iloc[0]\n",
    "\n",
    "        # Extract the numbers from the combined_cat_values string\n",
    "        numbers = ''.join(filter(str.isdigit, combined_cat_values))\n",
    "\n",
    "        # Insert an underscore between the numbers\n",
    "        formatted_numbers = '_'.join(numbers)\n",
    "\n",
    "        # Construct the filename\n",
    "        csv_filename = output_loc+f\"results_cat_{formatted_numbers}.csv\"\n",
    "\n",
    "        # Check if the file exists, if not, create it and write the header\n",
    "        if not os.path.exists(csv_filename):\n",
    "            with open(csv_filename, 'w', newline='') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                # Write header\n",
    "                csv_writer.writerow([\"Region Name\", \"Start Year\", \"End Year\",\"months_after\",  \"Consecutive Months Threshold\", \"combined_cat_values\", \"Parameter\", \"Median p-value\", \"Median median difference\", \"Median standard deviation\", \"Significance\", \"HW Start Date\", \"HW End Date\"])\n",
    "\n",
    "        # Append data to CSV\n",
    "        with open(csv_filename, 'a', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            # Write data rows\n",
    "            csv_writer.writerows(results)\n",
    "\n",
    "        print(\"Results for\", variable, \"in\", region_name, \"appended to\", csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0f3fbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    start_year   end_year   longhurst_region_code  region_name   \\\n",
      "0          2016       2017                      53         ANTA   \n",
      "1          2016       2017                      53         ANTA   \n",
      "2          2016       2017                      53         ANTA   \n",
      "3          2016       2017                      53         ANTA   \n",
      "4          2016       2017                      53         ANTA   \n",
      "5          2016       2017                      53         ANTA   \n",
      "6          2016       2017                      53         ANTA   \n",
      "7          2016       2017                      53         ANTA   \n",
      "8          2016       2017                      53         ANTA   \n",
      "9          2016       2017                      53         ANTA   \n",
      "10         2016       2017                      53         ANTA   \n",
      "11         2016       2017                      53         ANTA   \n",
      "\n",
      "   combined_cat_values   consecutive_months_threshold   num_samples  \\\n",
      "0                [3, 4]                              3          100   \n",
      "1                [3, 4]                              3          100   \n",
      "2                [3, 4]                              3          100   \n",
      "3                [3, 4]                              3          100   \n",
      "4                [3, 4]                              3          100   \n",
      "5                [3, 4]                              3          100   \n",
      "6                [3, 4]                              3          100   \n",
      "7                [3, 4]                              3          100   \n",
      "8                [3, 4]                              3          100   \n",
      "9                [3, 4]                              3          100   \n",
      "10               [3, 4]                              3          100   \n",
      "11               [3, 4]                              3          100   \n",
      "\n",
      "    months_after  \n",
      "0              1  \n",
      "1              2  \n",
      "2              3  \n",
      "3              4  \n",
      "4              5  \n",
      "5              6  \n",
      "6              7  \n",
      "7              8  \n",
      "8              9  \n",
      "9             10  \n",
      "10            11  \n",
      "11            12  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\df391\\AppData\\Local\\Temp\\ipykernel_37492\\2406659140.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  variable_data.sort_values(by='months_after', inplace=True)\n",
      "C:\\Users\\df391\\AppData\\Local\\Temp\\ipykernel_37492\\2406659140.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  variable_data.sort_values(by='months_after', inplace=True)\n",
      "C:\\Users\\df391\\AppData\\Local\\Temp\\ipykernel_37492\\2406659140.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  variable_data.sort_values(by='months_after', inplace=True)\n",
      "C:\\Users\\df391\\AppData\\Local\\Temp\\ipykernel_37492\\2406659140.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  variable_data.sort_values(by='months_after', inplace=True)\n",
      "C:\\Users\\df391\\AppData\\Local\\Temp\\ipykernel_37492\\2406659140.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  variable_data.sort_values(by='months_after', inplace=True)\n",
      "C:\\Users\\df391\\AppData\\Local\\Temp\\ipykernel_37492\\2406659140.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  variable_data.sort_values(by='months_after', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Extract combined category values from the first row of the 'combined_cat_values' column\n",
    "csv_file_path = \"C:/Users/df391/OneDrive - University of Exeter/Post_Doc_Ocean_Health/HeatwaveAnalysis/PARAMETERS.csv\"  # Replace with the actual path\n",
    "output_loc = 'D:/OceanHealth/output/'\n",
    "parameters_df = pd.read_csv(csv_file_path)\n",
    "print(parameters_df)\n",
    "combined_cat_values = parameters_df['combined_cat_values '].iloc[0]\n",
    "\n",
    "# Extract the numbers from the combined_cat_values string\n",
    "numbers = ''.join(filter(str.isdigit, combined_cat_values))\n",
    "\n",
    "# Insert an underscore between the numbers\n",
    "formatted_numbers = '_'.join(numbers)\n",
    "\n",
    "data = pd.read_csv(output_loc+ f\"results_cat_{formatted_numbers}.csv\")\n",
    "\n",
    "# Separate data by variable\n",
    "variables = data['Parameter'].unique()\n",
    "\n",
    "# Iterate over regions and create separate plots for each\n",
    "for region in data['Region Name'].unique():\n",
    "    region_data = data[data['Region Name'] == region]\n",
    "    start_year = region_data['Start Year'].min()\n",
    "    end_year = region_data['End Year'].max()\n",
    "    combined_cat_values = region_data['combined_cat_values']\n",
    "\n",
    "    fig, axs = plt.subplots(len(variables), 1, figsize=(8, 2 * len(variables)), sharex=False)\n",
    "    fig.suptitle(f'Region: {region} ({start_year}-{end_year})', y=1.02, fontsize=16, ha='center')  # Place region name and year on top of the plots with increased font size\n",
    "\n",
    "    for i, variable in enumerate(variables):\n",
    "        # Filter data for the specific variable and region\n",
    "        variable_data = region_data[region_data['Parameter'] == variable]\n",
    "\n",
    "        # Sort the data by Months After for a better visualization\n",
    "        variable_data.sort_values(by='months_after', inplace=True)\n",
    "\n",
    "        # Create a step digital signal plot with bolder lines\n",
    "        x_values = variable_data['months_after']\n",
    "        y_values = (variable_data['Significance'] == \"Significant\").astype(int)\n",
    "\n",
    "        axs[i].step(x_values, y_values, where='post', color='darkblue', linewidth=2.5)  # Make the lines bolder\n",
    "\n",
    "        axs[i].set_title(f'Change in significance for {variable}', fontsize=14)  # Adjust title fontsize\n",
    "        axs[i].set_yticks([0, 1])\n",
    "        axs[i].set_ylim([-0.1, 1.1])  # Ensure the y-axis range is fixed\n",
    "\n",
    "        # Make ticks and tick labels bold\n",
    "        axs[i].tick_params(axis='both', which='major', labelsize=10, width=1.5, length=6)  # Adjust tick parameters\n",
    "\n",
    "    # Write region name on top of the entire figure\n",
    "    fig.text(0.5, 0.98, f'Region: {region}', fontsize=12, ha='center')\n",
    "\n",
    "    # Set common labels for y axis\n",
    "    fig.text(-0.04, 0.5, 'Significance (1: Significant, 0: Non-Significant)', va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "    # Set custom x labels for all subplots\n",
    "    for ax in axs:\n",
    "        ax.set_xticks(data['months_after'].unique())\n",
    "        ax.set_xticklabels(data['months_after'].unique().astype(str))\n",
    "\n",
    "    # Place the plots for \"spco2\" and \"alkalinity\" at the bottom\n",
    "    axs[-1].set_xlabel('Months', fontsize=12)  # Adjust xlabel fontsize\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot as an image file with region name and year\n",
    "    filename = output_loc+ f'plots/{region}_{start_year}-{end_year}_cat_{formatted_numbers}_plots.png'\n",
    "    fig.savefig(filename)\n",
    "    \n",
    "    # Close the figure to release memory\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc0b91f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90aa3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define parameters for analysis\n",
    "start_year = 2014\n",
    "end_year = 2015\n",
    "longhurst_region_code = 38\n",
    "region_name = \"NPTG\"\n",
    "combined_cat_values = [3, 4]  # Magnitude of heatwave categories to consider\n",
    "num_samples = 100  \n",
    "consecutive_months_threshold = 1\n",
    "\n",
    "# Section 1: Load and Preprocess Data\n",
    "# Load the netCDF file containing variables other than chlorophyll\n",
    "dataset = xr.open_dataset('/Users/sayooj/Downloads/GlobalAtlas_MHW_ESACCISST_1deg_1982-2021.nc', decode_times=False)\n",
    "\n",
    "# Define the start and end indices for slicing\n",
    "start_idx = (start_year - 1982) * 365\n",
    "end_idx = start_idx + (end_year - start_year + 1) * 365 - 1\n",
    "\n",
    "# Create a new dataset with data only for the specified time range\n",
    "new_dataset = dataset.isel(time=slice(start_idx, end_idx + 1))\n",
    "\n",
    "# Convert data variables to float32 if needed\n",
    "new_dataset['cat'] = new_dataset['cat'].astype('float32')\n",
    "new_dataset['mhw'] = new_dataset['mhw'].astype('float32')\n",
    "\n",
    "# Save the new dataset to a new netCDF file\n",
    "new_dataset.to_netcdf(f'/Users/sayooj/Downloads/{region_name}_{start_year}_{end_year}.nc')\n",
    "\n",
    "# Section 2: Mask Based on Longhurst Regions\n",
    "# Open the Longhurst region file\n",
    "longhurst_file = '/Users/sayooj/Downloads/Longhurst_1_deg.nc'\n",
    "longhurst_dataset = xr.open_dataset(longhurst_file)\n",
    "\n",
    "# Read the Longhurst variable\n",
    "longhurst = longhurst_dataset['longhurst'].values\n",
    "\n",
    "# Create a mask based on Longhurst regions and transpose it\n",
    "mask = np.isin(longhurst, [longhurst_region_code]).T\n",
    "\n",
    "# Apply the mask to the entire time range\n",
    "masked_dataset = new_dataset.where(mask)\n",
    "\n",
    "# Save the masked data to a new netCDF file\n",
    "masked_file_path = f'/Users/sayooj/Downloads/masked_{region_name}_{start_year}_{end_year}.nc'\n",
    "masked_dataset.to_netcdf(masked_file_path)\n",
    "\n",
    "# Section 3: Create Monthly Masks with Values Only Inside Longhurst Region\n",
    "# Load the netCDF file containing the masked data\n",
    "masked_nc_file = xr.open_dataset(masked_file_path, decode_times=False)\n",
    "\n",
    "# Extract the masked cat variable and apply the Longhurst mask\n",
    "masked_cat = masked_nc_file['cat'].where(mask)\n",
    "\n",
    "# Calculate the number of months\n",
    "num_months = int(len(masked_nc_file['time']) / 30)\n",
    "\n",
    "# Create an empty array to store monthly masks\n",
    "monthly_masks = np.zeros((num_months, len(masked_nc_file['lat']), len(masked_nc_file['lon']))) * np.nan\n",
    "\n",
    "# Iterate over each month\n",
    "for month in range(num_months):\n",
    "    # Calculate the start and end indices for the current month\n",
    "    start_idx = month * 30\n",
    "    end_idx = (month + 1) * 30\n",
    "\n",
    "    # Extract the masked daily cat values for the current month\n",
    "    month_data = masked_cat[start_idx:end_idx]\n",
    "\n",
    "    # Find the maximum category occurrence for each lat-lon point in the current month\n",
    "    max_values = np.max(month_data, axis=0)\n",
    "\n",
    "    # Set areas impacted by the highest category occurrence within the Longhurst region\n",
    "    monthly_mask = np.where(mask, max_values, np.nan)\n",
    "\n",
    "    # Save the monthly mask\n",
    "    monthly_masks[month] = monthly_mask\n",
    "\n",
    "# Create a new netCDF file to save the monthly masks\n",
    "output_file = xr.Dataset(\n",
    "    data_vars={\n",
    "        'lat': ('lat', masked_nc_file['lat'].values),\n",
    "        'lon': ('lon', masked_nc_file['lon'].values),\n",
    "        'time': ('time', np.arange(1, num_months + 1)),\n",
    "        'monthly_masks': (['time', 'lat', 'lon'], monthly_masks)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add attributes\n",
    "output_file['lat'].attrs['units'] = 'degrees_north'\n",
    "output_file['lon'].attrs['units'] = 'degrees_east'\n",
    "output_file['time'].attrs['units'] = f'months since {start_year}-01-01'\n",
    "output_file['monthly_masks'].attrs['units'] = '1'\n",
    "output_file.attrs['description'] = f'Monthly masks for marine heatwaves in {region_name}'\n",
    "\n",
    "# Save the monthly masks to a new netCDF file\n",
    "output_file.to_netcdf(f'/Users/sayooj/Downloads/monthly_masks_{region_name}_{start_year}_{end_year}.nc')\n",
    "\n",
    "# Close the netCDF files\n",
    "masked_nc_file.close()\n",
    "\n",
    "# Section 4: Create Consecutive Monthly Mask for Values 3 or 4\n",
    "# Load the netCDF file containing the monthly masks\n",
    "monthly_masks_file = xr.open_dataset(f'/Users/sayooj/Downloads/monthly_masks_{region_name}_{start_year}_{end_year}.nc', decode_times=False)\n",
    "\n",
    "# Extract the monthly masks variable\n",
    "monthly_masks_data = monthly_masks_file['monthly_masks'].values\n",
    "\n",
    "# Initialize the consecutive monthly mask array\n",
    "consecutive_monthly_mask = np.zeros_like(monthly_masks) * np.nan\n",
    "\n",
    "# Iterate over each lat-lon point\n",
    "for lat_idx in range(monthly_masks_data.shape[1]):\n",
    "    for lon_idx in range(monthly_masks_data.shape[2]):\n",
    "        # Extract the monthly mask values for the current lat-lon point\n",
    "        values = monthly_masks_data[:, lat_idx, lon_idx]\n",
    "\n",
    "        consecutive_count = 0\n",
    "        consecutive_mask = np.zeros_like(values)\n",
    "\n",
    "        for i in range(len(values)):\n",
    "            if (values[i] == 3) or (values[i] == 4):\n",
    "                consecutive_count += 1\n",
    "                consecutive_mask[i] = values[i]\n",
    "            else:\n",
    "                consecutive_count = 0\n",
    "                consecutive_mask[i] = 0\n",
    "\n",
    "            if consecutive_count >= consecutive_months_threshold:\n",
    "                break\n",
    "\n",
    "        # Set the consecutive monthly mask values for the current lat-lon point\n",
    "        consecutive_monthly_mask[:len(consecutive_mask), lat_idx, lon_idx] = consecutive_mask\n",
    "\n",
    "# Apply the Longhurst mask to set values inside the region to NaN\n",
    "consecutive_monthly_mask = np.where(mask, consecutive_monthly_mask, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "# Create a new netCDF file to save the consecutive monthly mask\n",
    "consecutive_monthly_mask_file = xr.Dataset(\n",
    "    data_vars={\n",
    "        'lat': ('lat', monthly_masks_file['lat'].values),\n",
    "        'lon': ('lon', monthly_masks_file['lon'].values),\n",
    "        'time': ('time', monthly_masks_file['time'].values),\n",
    "        'consecutive_monthly_mask': (['time', 'lat', 'lon'], consecutive_monthly_mask)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add attributes\n",
    "consecutive_monthly_mask_file['lat'].attrs['units'] = 'degrees_north'\n",
    "consecutive_monthly_mask_file['lon'].attrs['units'] = 'degrees_east'\n",
    "consecutive_monthly_mask_file['time'].attrs['units'] = f'months since {start_year}-01-01'\n",
    "consecutive_monthly_mask_file['consecutive_monthly_mask'].attrs['units'] = '1'\n",
    "consecutive_monthly_mask_file.attrs['description'] = f'Consecutive monthly mask for values 3 or 4 in {region_name}'\n",
    "\n",
    "# Save the consecutive monthly mask to a new netCDF file\n",
    "consecutive_monthly_mask_file.to_netcdf(f'/Users/sayooj/Downloads/consecutive_monthly_mask_{region_name}_{start_year}_{end_year}.nc')\n",
    "\n",
    "# Close the netCDF files\n",
    "monthly_masks_file.close()\n",
    "consecutive_monthly_mask_file.close()\n",
    "\n",
    "# Initialize a list to store information about consecutive heatwaves\n",
    "consecutive_heatwave_info = []\n",
    "\n",
    "# Iterate over each lat-lon point\n",
    "for lat_idx in range(consecutive_monthly_mask.shape[1]):\n",
    "    for lon_idx in range(consecutive_monthly_mask.shape[2]):\n",
    "        # Extract the consecutive monthly mask values for the current lat-lon point\n",
    "        values = consecutive_monthly_mask[:, lat_idx, lon_idx]\n",
    "\n",
    "        # Find indices where consecutive heatwaves occurred (values 3 or 4)\n",
    "        heatwave_indices = np.where(np.isin(values, [3, 4]))[0]\n",
    "\n",
    "        # If consecutive heatwaves occurred at this lat-lon point\n",
    "        if len(heatwave_indices) >= consecutive_months_threshold:\n",
    "            # Get the corresponding dates for the identified indices\n",
    "            heatwave_dates = monthly_masks_file['time'].values[heatwave_indices]\n",
    "\n",
    "            # Convert months to dates based on the start_year\n",
    "            start_date = pd.to_datetime(f'{start_year}-01-01')\n",
    "            exact_dates = [(start_date + pd.DateOffset(months=int(month))).strftime('%Y-%m-%d') for month in heatwave_dates]\n",
    "\n",
    "            # Append the lat, lon, months, and exact_dates to the list\n",
    "            consecutive_heatwave_info.append({\n",
    "                'lat': monthly_masks_file['lat'].values[lat_idx],\n",
    "                'lon': monthly_masks_file['lon'].values[lon_idx],\n",
    "                'months': heatwave_dates.tolist(),\n",
    "                'exact_dates': exact_dates\n",
    "            })\n",
    "\n",
    "# Create a DataFrame with the extracted information\n",
    "consecutive_heatwave_info_df = pd.DataFrame(consecutive_heatwave_info)\n",
    "\n",
    "# Save the DataFrame to a CSV file with region name, start year, and end year in the filename\n",
    "csv_file_path = f'/Users/sayooj/Downloads/consecutive_heatwave_info_{region_name}_{start_year}_{end_year}.csv'\n",
    "consecutive_heatwave_info_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "\n",
    "# Section 4: Create Consecutive Monthly Mask for Values 3 or 4\n",
    "# Load the netCDF file containing the monthly masks\n",
    "monthly_masks_file = xr.open_dataset(f'/Users/sayooj/Downloads/monthly_masks_{region_name}_{start_year}_{end_year}.nc', decode_times=False)\n",
    "\n",
    "# Extract the monthly masks variable\n",
    "monthly_masks_data = monthly_masks_file['monthly_masks'].values\n",
    "\n",
    "# Initialize the consecutive monthly mask array\n",
    "consecutive_monthly_mask = np.zeros_like(monthly_masks) * np.nan\n",
    "\n",
    "# Iterate over each lat-lon point\n",
    "for lat_idx in range(monthly_masks_data.shape[1]):\n",
    "    for lon_idx in range(monthly_masks_data.shape[2]):\n",
    "        # Extract the monthly mask values for the current lat-lon point\n",
    "        values = monthly_masks_data[:, lat_idx, lon_idx]\n",
    "\n",
    "        consecutive_count = 0\n",
    "        consecutive_mask = np.zeros_like(values)\n",
    "\n",
    "        for i in range(len(values)):\n",
    "            if (values[i] == 3) or (values[i] == 4):\n",
    "                consecutive_count += 1\n",
    "                consecutive_mask[i] = values[i]\n",
    "            else:\n",
    "                consecutive_count = 0\n",
    "                consecutive_mask[i] = 0\n",
    "\n",
    "            if consecutive_count >= consecutive_months_threshold:\n",
    "                break\n",
    "\n",
    "        # Set the consecutive monthly mask values for the current lat-lon point\n",
    "        consecutive_monthly_mask[:len(consecutive_mask), lat_idx, lon_idx] = consecutive_mask\n",
    "\n",
    "# Apply the Longhurst mask to set values inside the region to NaN\n",
    "consecutive_monthly_mask = np.where(mask, consecutive_monthly_mask, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "# Create a new netCDF file to save the consecutive monthly mask\n",
    "consecutive_monthly_mask_file = xr.Dataset(\n",
    "    data_vars={\n",
    "        'lat': ('lat', monthly_masks_file['lat'].values),\n",
    "        'lon': ('lon', monthly_masks_file['lon'].values),\n",
    "        'time': ('time', monthly_masks_file['time'].values),\n",
    "        'consecutive_monthly_mask': (['time', 'lat', 'lon'], consecutive_monthly_mask)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add attributes\n",
    "consecutive_monthly_mask_file['lat'].attrs['units'] = 'degrees_north'\n",
    "consecutive_monthly_mask_file['lon'].attrs['units'] = 'degrees_east'\n",
    "consecutive_monthly_mask_file['time'].attrs['units'] = f'months since {start_year}-01-01'\n",
    "consecutive_monthly_mask_file['consecutive_monthly_mask'].attrs['units'] = '1'\n",
    "consecutive_monthly_mask_file.attrs['description'] = f'Consecutive monthly mask for values 3 or 4 in {region_name}'\n",
    "\n",
    "# Save the consecutive monthly mask to a new netCDF file\n",
    "consecutive_monthly_mask_file.to_netcdf(f'/Users/sayooj/Downloads/consecutive_monthly_mask_{region_name}_{start_year}_{end_year}.nc')\n",
    "\n",
    "# Close the netCDF files\n",
    "monthly_masks_file.close()\n",
    "consecutive_monthly_mask_file.close()\n",
    "\n",
    "# Initialize a list to store information about consecutive heatwaves\n",
    "consecutive_heatwave_info = []\n",
    "\n",
    "# Iterate over each lat-lon point\n",
    "for lat_idx in range(consecutive_monthly_mask.shape[1]):\n",
    "    for lon_idx in range(consecutive_monthly_mask.shape[2]):\n",
    "        # Extract the consecutive monthly mask values for the current lat-lon point\n",
    "        values = consecutive_monthly_mask[:, lat_idx, lon_idx]\n",
    "\n",
    "        # Find indices where consecutive heatwaves occurred (values 3 or 4)\n",
    "        heatwave_indices = np.where(np.isin(values, [3, 4]))[0]\n",
    "\n",
    "        # If consecutive heatwaves occurred at this lat-lon point\n",
    "        if len(heatwave_indices) >= consecutive_months_threshold:\n",
    "            # Get the corresponding dates for the identified indices\n",
    "            heatwave_dates = monthly_masks_file['time'].values[heatwave_indices]\n",
    "\n",
    "            # Convert months to dates based on the start_year\n",
    "            start_date = pd.to_datetime(f'{start_year}-01-01')\n",
    "            exact_dates = [(start_date + pd.DateOffset(months=int(month))).strftime('%Y-%m-%d') for month in heatwave_dates]\n",
    "\n",
    "            # Append the lat, lon, months, and exact_dates to the list\n",
    "            consecutive_heatwave_info.append({\n",
    "                'lat': monthly_masks_file['lat'].values[lat_idx],\n",
    "                'lon': monthly_masks_file['lon'].values[lon_idx],\n",
    "                'months': heatwave_dates.tolist(),\n",
    "                'exact_dates': exact_dates\n",
    "            })\n",
    "\n",
    "# Create a DataFrame with the extracted information\n",
    "consecutive_heatwave_info_df = pd.DataFrame(consecutive_heatwave_info)\n",
    "\n",
    "# Save the DataFrame to a CSV file with region name, start year, and end year in the filename\n",
    "csv_file_path = f'/Users/sayooj/Downloads/consecutive_heatwave_info_{region_name}_{start_year}_{end_year}.csv'\n",
    "consecutive_heatwave_info_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Section 4: Statistical Analysis\n",
    "# Open the heatwave dataset file\n",
    "heatwave_dataset_file = nc.Dataset('/Users/sayooj/Downloads/OceanSODA-ETHZ_GRaCER_v2021a_1982-2020.nc')\n",
    "\n",
    "# Open the non-heatwave dataset file\n",
    "non_heatwave_dataset_file = nc.Dataset('/Users/sayooj/Downloads/all_variables_monthly_avg_overall.nc')\n",
    "\n",
    "# Get the variable data\n",
    "fgco2 = heatwave_dataset_file.variables['fgco2'][:]\n",
    "ph = heatwave_dataset_file.variables['ph_total'][:]\n",
    "aragonite_saturation = heatwave_dataset_file.variables['omega_ar'][:]\n",
    "sst = heatwave_dataset_file.variables['temperature'][:]\n",
    "\n",
    "# Create the time axis for the specified years\n",
    "dates = pd.date_range(start='{}-01-01'.format(start_year), end='{}-12-31'.format(end_year), freq='M')\n",
    "\n",
    "# Find the indices corresponding to the time period\n",
    "indices_year = np.where(dates.year.isin([start_year, end_year]))[0]\n",
    "\n",
    "# Slice the data for the specified years\n",
    "fgco2_year = fgco2[indices_year]\n",
    "sst_year = sst[indices_year]\n",
    "ph_year = ph[indices_year]\n",
    "aragonite_saturation_year = aragonite_saturation[indices_year]\n",
    "\n",
    "# Open the mask file for the specified region\n",
    "mask_file = nc.Dataset(f'/Users/sayooj/Downloads/consecutive_monthly_mask_{region_name}_{start_year}_{end_year}.nc')\n",
    "\n",
    "# Get the mask variable for the specified region\n",
    "mask_region = mask_file.variables['consecutive_monthly_mask'][:]\n",
    "\n",
    "# Get indices where the mask values are equal to any of the specified cat values (e.g., heatwave period)\n",
    "indices_heatwave_region_year = np.where(np.isin(mask_region, combined_cat_values))[0]\n",
    "\n",
    "# Get indices where the mask values are not equal to any of the specified cat values (e.g., non-heatwave period)\n",
    "indices_non_heatwave_region_year = np.where(~np.isin(mask_region, combined_cat_values))[0]\n",
    "\n",
    "# Apply the mask to the sliced data\n",
    "fgco2_masked_year = np.ma.masked_array(fgco2_year, np.logical_not(mask_region))\n",
    "sst_masked_year = np.ma.masked_array(sst_year, np.logical_not(mask_region))\n",
    "ph_masked_year = np.ma.masked_array(ph_year, np.logical_not(mask_region))\n",
    "aragonite_saturation_masked_year = np.ma.masked_array(aragonite_saturation_year, np.logical_not(mask_region))\n",
    "\n",
    "# Calculate median values with the mask for fgco2\n",
    "fgco2_median_region_year = np.ma.median(fgco2_masked_year, axis=(1, 2))\n",
    "\n",
    "# Calculate median values with the mask for sst\n",
    "sst_median_region_year = np.ma.median(sst_masked_year, axis=(1, 2))\n",
    "\n",
    "# Calculate median values with the mask for ph\n",
    "ph_median_region_year = np.ma.median(ph_masked_year, axis=(1, 2))\n",
    "\n",
    "# Calculate median values with the mask for aragonite saturation\n",
    "aragonite_saturation_median_region_year = np.ma.median(aragonite_saturation_masked_year, axis=(1, 2))\n",
    "\n",
    "# Perform the Wilcoxon signed-rank tests for fgco2\n",
    "p_values_region_year = []\n",
    "median_diff_region_year = []\n",
    "std_dev_region_year = []\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    # Randomly select indices for heatwave and non-heatwave periods\n",
    "    sample_indices_region_heatwave_year = np.random.choice(indices_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "    sample_indices_region_non_heatwave_year = np.random.choice(indices_non_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "\n",
    "    # Filter the data based on the sampled indices for fgco2\n",
    "    sample_fgco2_median_region_heatwave_year = fgco2_median_region_year[sample_indices_region_heatwave_year]\n",
    "    sample_fgco2_median_region_non_heatwave_year = fgco2_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "    # Perform the Wilcoxon signed-rank tests for fgco2\n",
    "    _, p_value_region_year = wilcoxon(sample_fgco2_median_region_heatwave_year, sample_fgco2_median_region_non_heatwave_year)\n",
    "\n",
    "    # Calculate the median difference and standard deviation for fgco2\n",
    "    median_diff_region_year.append(np.median(sample_fgco2_median_region_heatwave_year - sample_fgco2_median_region_non_heatwave_year))\n",
    "    std_dev_region_year.append(np.std(sample_fgco2_median_region_heatwave_year - sample_fgco2_median_region_non_heatwave_year))\n",
    "\n",
    "    # Append the p-value to the respective list for fgco2\n",
    "    p_values_region_year.append(p_value_region_year)\n",
    "\n",
    "# Calculate the median p-value, median difference, and median standard deviation for fgco2\n",
    "median_p_value_fgco2_region_year = np.median(p_values_region_year)\n",
    "median_median_diff_fgco2_region_year = np.median(median_diff_region_year)\n",
    "median_std_dev_fgco2_region_year = np.median(std_dev_region_year)\n",
    "\n",
    "# Perform the Wilcoxon signed-rank tests for sst\n",
    "p_values_region_year = []\n",
    "median_diff_region_year = []\n",
    "std_dev_region_year = []\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    # Randomly select indices for heatwave and non-heatwave periods\n",
    "    sample_indices_region_heatwave_year = np.random.choice(indices_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "    sample_indices_region_non_heatwave_year = np.random.choice(indices_non_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "\n",
    "    # Filter the data based on the sampled indices for sst\n",
    "    sample_sst_median_region_heatwave_year = sst_median_region_year[sample_indices_region_heatwave_year]\n",
    "    sample_sst_median_region_non_heatwave_year = sst_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "    # Perform the Wilcoxon signed-rank tests for sst\n",
    "    _, p_value_region_year = wilcoxon(sample_sst_median_region_heatwave_year, sample_sst_median_region_non_heatwave_year)\n",
    "\n",
    "    # Calculate the median difference and standard deviation for sst\n",
    "    median_diff_region_year.append(np.median(sample_sst_median_region_heatwave_year - sample_sst_median_region_non_heatwave_year))\n",
    "    std_dev_region_year.append(np.std(sample_sst_median_region_heatwave_year - sample_sst_median_region_non_heatwave_year))\n",
    "\n",
    "    # Append the p-value to the respective list for sst\n",
    "    p_values_region_year.append(p_value_region_year)\n",
    "\n",
    "# Calculate the median p-value, median difference, and median standard deviation for sst\n",
    "median_p_value_sst_region_year = np.median(p_values_region_year)\n",
    "median_median_diff_sst_region_year = np.median(median_diff_region_year)\n",
    "median_std_dev_sst_region_year = np.median(std_dev_region_year)\n",
    "\n",
    "# Perform the Wilcoxon signed-rank tests for ph\n",
    "p_values_region_year = []\n",
    "median_diff_region_year = []\n",
    "std_dev_region_year = []\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    # Randomly select indices for heatwave and non-heatwave periods\n",
    "    sample_indices_region_heatwave_year = np.random.choice(indices_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "    sample_indices_region_non_heatwave_year = np.random.choice(indices_non_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "\n",
    "    # Filter the data based on the sampled indices for ph\n",
    "    sample_ph_median_region_heatwave_year = ph_median_region_year[sample_indices_region_heatwave_year]\n",
    "    sample_ph_median_region_non_heatwave_year = ph_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "    # Perform the Wilcoxon signed-rank tests for ph\n",
    "    _, p_value_region_year = wilcoxon(sample_ph_median_region_heatwave_year, sample_ph_median_region_non_heatwave_year)\n",
    "\n",
    "    # Calculate the median difference and standard deviation for ph\n",
    "    median_diff_region_year.append(np.median(sample_ph_median_region_heatwave_year - sample_ph_median_region_non_heatwave_year))\n",
    "    std_dev_region_year.append(np.std(sample_ph_median_region_heatwave_year - sample_ph_median_region_non_heatwave_year))\n",
    "\n",
    "    # Append the p-value to the respective list for ph\n",
    "    p_values_region_year.append(p_value_region_year)\n",
    "\n",
    "# Calculate the median p-value, median difference, and median standard deviation for ph\n",
    "median_p_value_ph_region_year = np.median(p_values_region_year)\n",
    "median_median_diff_ph_region_year = np.median(median_diff_region_year)\n",
    "median_std_dev_ph_region_year = np.median(std_dev_region_year)\n",
    "\n",
    "# Perform the Wilcoxon signed-rank tests for aragonite saturation\n",
    "p_values_region_year = []\n",
    "median_diff_region_year = []\n",
    "std_dev_region_year = []\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    # Randomly select indices for heatwave and non-heatwave periods\n",
    "    sample_indices_region_heatwave_year = np.random.choice(indices_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "    sample_indices_region_non_heatwave_year = np.random.choice(indices_non_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "\n",
    "    # Filter the data based on the sampled indices for aragonite saturation\n",
    "    sample_aragonite_saturation_median_region_heatwave_year = aragonite_saturation_median_region_year[sample_indices_region_heatwave_year]\n",
    "    sample_aragonite_saturation_median_region_non_heatwave_year = aragonite_saturation_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "    # Perform the Wilcoxon signed-rank tests for aragonite saturation\n",
    "    _, p_value_region_year = wilcoxon(sample_aragonite_saturation_median_region_heatwave_year, sample_aragonite_saturation_median_region_non_heatwave_year)\n",
    "\n",
    "    # Calculate the median difference and standard deviation for aragonite saturation\n",
    "    median_diff_region_year.append(np.median(sample_aragonite_saturation_median_region_heatwave_year - sample_aragonite_saturation_median_region_non_heatwave_year))\n",
    "    std_dev_region_year.append(np.std(sample_aragonite_saturation_median_region_heatwave_year - sample_aragonite_saturation_median_region_non_heatwave_year))\n",
    "\n",
    "    # Append the p-value to the respective list for aragonite saturation\n",
    "    p_values_region_year.append(p_value_region_year)\n",
    "\n",
    "# Calculate the median p-value, median difference, and median standard deviation for aragonite saturation\n",
    "median_p_value_aragonite_saturation_region_year = np.median(p_values_region_year)\n",
    "median_median_diff_aragonite_saturation_region_year = np.median(median_diff_region_year)\n",
    "median_std_dev_aragonite_saturation_region_year = np.median(std_dev_region_year)\n",
    "\n",
    "# Define precision values for each variable (replace these with actual precision values from the paper)\n",
    "precision_sst = 0.01\n",
    "precision_fgco2 = 0.01 \n",
    "precision_ph = 0.001 \n",
    "precision_aragonite_saturation = 0.01 \n",
    "precision_spco2 = 4\n",
    "precision_alkalinity = 5\n",
    "\n",
    "# Open the spco2 variable from the heatwave dataset file\n",
    "spco2 = heatwave_dataset_file.variables['spco2'][:]\n",
    "\n",
    "# Slice the spco2 data for the specified years\n",
    "spco2_year = spco2[indices_year]\n",
    "\n",
    "# Apply the mask to the sliced spco2 data\n",
    "spco2_masked_year = np.ma.masked_array(spco2_year, np.logical_not(mask_region))\n",
    "\n",
    "# Calculate median values with the mask for spco2\n",
    "spco2_median_region_year = np.ma.median(spco2_masked_year, axis=(1, 2))\n",
    "\n",
    "# Perform the Wilcoxon signed-rank tests for spco2\n",
    "p_values_region_year_spco2 = []\n",
    "median_diff_region_year_spco2 = []\n",
    "std_dev_region_year_spco2 = []\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    # Randomly select indices for heatwave and non-heatwave periods\n",
    "    sample_indices_region_heatwave_year = np.random.choice(indices_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "    sample_indices_region_non_heatwave_year = np.random.choice(indices_non_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "\n",
    "    # Filter the data based on the sampled indices for spco2\n",
    "    sample_spco2_median_region_heatwave_year = spco2_median_region_year[sample_indices_region_heatwave_year]\n",
    "    sample_spco2_median_region_non_heatwave_year = spco2_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "    # Perform the Wilcoxon signed-rank tests for spco2\n",
    "    _, p_value_region_year_spco2 = wilcoxon(sample_spco2_median_region_heatwave_year, sample_spco2_median_region_non_heatwave_year)\n",
    "\n",
    "    # Calculate the median difference and standard deviation for spco2\n",
    "    median_diff_region_year_spco2.append(np.median(sample_spco2_median_region_heatwave_year - sample_spco2_median_region_non_heatwave_year))\n",
    "    std_dev_region_year_spco2.append(np.std(sample_spco2_median_region_heatwave_year - sample_spco2_median_region_non_heatwave_year))\n",
    "\n",
    "    # Append the p-value to the respective list for spco2\n",
    "    p_values_region_year_spco2.append(p_value_region_year_spco2)\n",
    "\n",
    "# Calculate the median p-value, median difference, and median standard deviation for spco2\n",
    "median_p_value_spco2_region_year = np.median(p_values_region_year_spco2)\n",
    "median_median_diff_spco2_region_year = np.median(median_diff_region_year_spco2)\n",
    "median_std_dev_spco2_region_year = np.median(std_dev_region_year_spco2)\n",
    "\n",
    "\n",
    "# Get the alkalinity data\n",
    "alkalinity = heatwave_dataset_file.variables['talk'][:]\n",
    "\n",
    "# Slice the alkalinity data for the specified years\n",
    "alkalinity_year = alkalinity[indices_year]\n",
    "\n",
    "# Apply the mask to the sliced alkalinity data\n",
    "alkalinity_masked_year = np.ma.masked_array(alkalinity_year, np.logical_not(mask_region))\n",
    "\n",
    "# Calculate median values with the mask for alkalinity\n",
    "alkalinity_median_region_year = np.ma.median(alkalinity_masked_year, axis=(1, 2))\n",
    "\n",
    "# Perform the Wilcoxon signed-rank tests for alkalinity\n",
    "p_values_region_year_alkalinity = []\n",
    "median_diff_region_year_alkalinity = []\n",
    "std_dev_region_year_alkalinity = []\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    # Randomly select indices for heatwave and non-heatwave periods\n",
    "    sample_indices_region_heatwave_year = np.random.choice(indices_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "    sample_indices_region_non_heatwave_year = np.random.choice(indices_non_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "\n",
    "    # Filter the data based on the sampled indices for alkalinity\n",
    "    sample_alkalinity_median_region_heatwave_year = alkalinity_median_region_year[sample_indices_region_heatwave_year]\n",
    "    sample_alkalinity_median_region_non_heatwave_year = alkalinity_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "    # Perform the Wilcoxon signed-rank tests for alkalinity\n",
    "    _, p_value_region_year_alkalinity = wilcoxon(sample_alkalinity_median_region_heatwave_year, sample_alkalinity_median_region_non_heatwave_year)\n",
    "\n",
    "    # Calculate the median difference and standard deviation for alkalinity\n",
    "    median_diff_region_year_alkalinity.append(np.median(sample_alkalinity_median_region_heatwave_year - sample_alkalinity_median_region_non_heatwave_year))\n",
    "    std_dev_region_year_alkalinity.append(np.std(sample_alkalinity_median_region_heatwave_year - sample_alkalinity_median_region_non_heatwave_year))\n",
    "\n",
    "    # Append the p-value to the respective list for alkalinity\n",
    "    p_values_region_year_alkalinity.append(p_value_region_year_alkalinity)\n",
    "\n",
    "# Calculate the median p-value, median difference, and median standard deviation for alkalinity\n",
    "median_p_value_alkalinity_region_year = np.median(p_values_region_year_alkalinity)\n",
    "median_median_diff_alkalinity_region_year = np.median(median_diff_region_year_alkalinity)\n",
    "median_std_dev_alkalinity_region_year = np.median(std_dev_region_year_alkalinity)\n",
    "\n",
    "# Define filter functions\n",
    "def apply_filter(median_diff, precision):\n",
    "    return abs(median_diff) >= precision\n",
    "\n",
    "# Apply filter for SST\n",
    "if apply_filter(median_median_diff_sst_region_year, precision_sst):\n",
    "    print(\"\\nResults for SST in {} in {}/{} pass the quality filter:\".format(region_name, start_year, end_year))\n",
    "    print(\"Median p-value:\", median_p_value_sst_region_year)\n",
    "    print(\"Median median difference:\", median_median_diff_sst_region_year)\n",
    "    print(\"Median standard deviation:\", median_std_dev_sst_region_year)\n",
    "else:\n",
    "    print(\"\\nResults for SST in {} in {}/{} do not pass the quality filter.\".format(region_name, start_year, end_year))\n",
    "\n",
    "# Apply filter for fgco2\n",
    "if apply_filter(median_median_diff_fgco2_region_year, precision_fgco2):\n",
    "    print(\"\\nResults for fgco2 in {} in {}/{} pass the quality filter:\".format(region_name, start_year, end_year))\n",
    "    print(\"Median p-value:\", median_p_value_fgco2_region_year)\n",
    "    print(\"Median median difference:\", median_median_diff_fgco2_region_year)\n",
    "    print(\"Median standard deviation:\", median_std_dev_fgco2_region_year)\n",
    "else:\n",
    "    print(\"\\nResults for fgco2 in {} in {}/{} do not pass the quality filter.\".format(region_name, start_year, end_year))\n",
    "\n",
    "# Apply filter for pH\n",
    "if apply_filter(median_median_diff_ph_region_year, precision_ph):\n",
    "    print(\"\\nResults for pH in {} in {}/{} pass the quality filter:\".format(region_name, start_year, end_year))\n",
    "    print(\"Median p-value:\", median_p_value_ph_region_year)\n",
    "    print(\"Median median difference:\", median_median_diff_ph_region_year)\n",
    "    print(\"Median standard deviation:\", median_std_dev_ph_region_year)\n",
    "else:\n",
    "    print(\"\\nResults for pH in {} in {}/{} do not pass the quality filter.\".format(region_name, start_year, end_year))\n",
    "\n",
    "# Apply filter for aragonite saturation\n",
    "if apply_filter(median_median_diff_aragonite_saturation_region_year, precision_aragonite_saturation):\n",
    "    print(\"\\nResults for aragonite saturation in {} in {}/{} pass the quality filter:\".format(region_name, start_year, end_year))\n",
    "    print(\"Median p-value:\", median_p_value_aragonite_saturation_region_year)\n",
    "    print(\"Median median difference:\", median_median_diff_aragonite_saturation_region_year)\n",
    "    print(\"Median standard deviation:\", median_std_dev_aragonite_saturation_region_year)\n",
    "else:\n",
    "    print(\"\\nResults for aragonite saturation in {} in {}/{} do not pass the quality filter.\".format(region_name, start_year, end_year))\n",
    "\n",
    "# Apply filter for spco2\n",
    "if apply_filter(median_median_diff_spco2_region_year, precision_spco2):\n",
    "    print(\"\\nResults for spco2 in {} in {}/{} pass the quality filter:\".format(region_name, start_year, end_year))\n",
    "    print(\"Median p-value:\", median_p_value_spco2_region_year)\n",
    "    print(\"Median median difference:\", median_median_diff_spco2_region_year)\n",
    "    print(\"Median standard deviation:\", median_std_dev_spco2_region_year)\n",
    "else:\n",
    "    print(\"\\nResults for spco2 in {} in {}/{} do not pass the quality filter.\".format(region_name, start_year, end_year))\n",
    "\n",
    "# Apply filter for alkalinity\n",
    "if apply_filter(median_median_diff_alkalinity_region_year, precision_alkalinity):\n",
    "    print(\"\\nResults for alkalinity in {} in {}/{} pass the quality filter:\".format(region_name, start_year, end_year))\n",
    "    print(\"Median p-value:\", median_p_value_alkalinity_region_year)\n",
    "    print(\"Median median difference:\", median_median_diff_alkalinity_region_year)\n",
    "    print(\"Median standard deviation:\", median_std_dev_alkalinity_region_year)\n",
    "else:\n",
    "    print(\"\\nResults for alkalinity in {} in {}/{} do not pass the quality filter.\".format(region_name, start_year, end_year))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

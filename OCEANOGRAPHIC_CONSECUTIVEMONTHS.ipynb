{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section should only be run if you don't have file for monthly averages for all oceanographic variables\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "# Open the NetCDF file\n",
    "ds = xr.open_dataset('/Users/sayooj/Downloads/OceanSODA-ETHZ_GRaCER_v2021a_1982-2020.nc')\n",
    "\n",
    "# List of variables\n",
    "variables = ['fgco2', 'ph_total', 'omega_ar', 'temperature', 'spco2', 'talk']\n",
    "\n",
    "# Create an empty dataset to store the monthly averages for all variables\n",
    "monthly_avg_dataset = xr.Dataset()\n",
    "\n",
    "# Loop over each variable\n",
    "for variable in variables:\n",
    "    # Extract the variable\n",
    "    var_data = ds[variable]\n",
    "\n",
    "    # Resample to monthly frequency and calculate the mean for each month\n",
    "    monthly_avg = var_data.resample(time='M').mean(dim='time')\n",
    "\n",
    "    # Calculate the overall average for each month across all years\n",
    "    monthly_avg_overall = monthly_avg.groupby('time.month').mean(dim='time')\n",
    "\n",
    "    # Add the variable to the combined dataset\n",
    "    monthly_avg_dataset[variable] = monthly_avg_overall\n",
    "\n",
    "# Save the combined dataset to a new NetCDF file\n",
    "output_path = '/Users/sayooj/Downloads/all_variables_monthly_avg_overall.nc'\n",
    "monthly_avg_dataset.to_netcdf(output_path)\n",
    "print(f'Saved all variables monthly averages to {output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42f590",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Read parameter combinations from CSV file\n",
    "csv_file_path = \"/Users/sayooj/Downloads/PARAMETERS.csv\"  # Replace with the actual path\n",
    "parameters_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Remove extra spaces from column names\n",
    "parameters_df.columns = parameters_df.columns.str.strip()\n",
    "\n",
    "for index, row in parameters_df.iterrows():\n",
    "    start_year = row['start_year']\n",
    "    end_year = row['end_year']\n",
    "    longhurst_region_code = row['longhurst_region_code']\n",
    "    region_name = row['region_name']\n",
    "    combined_cat_values = [3, 4]\n",
    "    num_samples = row['num_samples']\n",
    "    consecutive_months_threshold = row['consecutive_months_threshold']\n",
    "    months_after = row['months_after']\n",
    "    \n",
    "    # Section 1: Load and Preprocess Data\n",
    "    # Load the netCDF file containing variables other than chlorophyll\n",
    "    dataset = xr.open_dataset('/Users/sayooj/Downloads/GlobalAtlas_MHW_ESACCISST_1deg_1982-2021.nc', decode_times=False)\n",
    "\n",
    "    # Define the start and end indices for slicing\n",
    "    start_idx = (start_year - 1982) * 365\n",
    "    end_idx = start_idx + (end_year - start_year + 1) * 365 - 1\n",
    "\n",
    "    # Create a new dataset with data only for the specified time range\n",
    "    new_dataset = dataset.isel(time=slice(start_idx, end_idx + 1))\n",
    "\n",
    "    # Convert data variables to float32 if needed\n",
    "    new_dataset['cat'] = new_dataset['cat'].astype('float32')\n",
    "    new_dataset['mhw'] = new_dataset['mhw'].astype('float32')\n",
    "\n",
    "    # Save the new dataset to a new netCDF file\n",
    "    new_dataset.to_netcdf(f'/Users/sayooj/Downloads/{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Section 2: Mask Based on Longhurst Regions\n",
    "    # Open the Longhurst region file\n",
    "    longhurst_file = '/Users/sayooj/Downloads/Longhurst_1_deg.nc'\n",
    "    longhurst_dataset = xr.open_dataset(longhurst_file)\n",
    "\n",
    "    # Read the Longhurst variable\n",
    "    longhurst = longhurst_dataset['longhurst'].values\n",
    "\n",
    "    # Create a mask based on Longhurst regions and transpose it\n",
    "    mask = np.isin(longhurst, [longhurst_region_code]).T\n",
    "\n",
    "    # Apply the mask to the entire time range\n",
    "    masked_dataset = new_dataset.where(mask)\n",
    "\n",
    "    # Save the masked data to a new netCDF file\n",
    "    masked_file_path = f'/Users/sayooj/Downloads/masked_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc'\n",
    "    masked_dataset.to_netcdf(masked_file_path)\n",
    "\n",
    "    # Section 3: Create Monthly Masks with Values Only Inside Longhurst Region\n",
    "    # Load the netCDF file containing the masked data\n",
    "    masked_nc_file = xr.open_dataset(masked_file_path, decode_times=False)\n",
    "\n",
    "    # Extract the masked cat variable and apply the Longhurst mask\n",
    "    masked_cat = masked_nc_file['cat'].where(mask)\n",
    "\n",
    "    # Calculate the number of months\n",
    "    num_months = int(len(masked_nc_file['time']) / 30)\n",
    "\n",
    "    # Create an empty array to store monthly masks\n",
    "    monthly_masks = np.zeros((num_months, len(masked_nc_file['lat']), len(masked_nc_file['lon']))) * np.nan\n",
    "\n",
    "    # Iterate over each month\n",
    "    for month in range(num_months):\n",
    "        # Calculate the start and end indices for the current month\n",
    "        start_idx = month * 30\n",
    "        end_idx = (month + 1) * 30\n",
    "\n",
    "        # Extract the masked daily cat values for the current month\n",
    "        month_data = masked_cat[start_idx:end_idx]\n",
    "\n",
    "        # Find the maximum category occurrence for each lat-lon point in the current month\n",
    "        max_values = np.max(month_data, axis=0)\n",
    "\n",
    "        # Set areas impacted by the highest category occurrence within the Longhurst region\n",
    "        monthly_mask = np.where(mask, max_values, np.nan)\n",
    "\n",
    "        # Save the monthly mask\n",
    "        monthly_masks[month] = monthly_mask\n",
    "\n",
    "    # Create a new netCDF file to save the monthly masks\n",
    "    output_file = xr.Dataset(\n",
    "        data_vars={\n",
    "            'lat': ('lat', masked_nc_file['lat'].values),\n",
    "            'lon': ('lon', masked_nc_file['lon'].values),\n",
    "            'time': ('time', np.arange(1, num_months + 1)),\n",
    "            'monthly_masks': (['time', 'lat', 'lon'], monthly_masks)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add attributes\n",
    "    output_file['lat'].attrs['units'] = 'degrees_north'\n",
    "    output_file['lon'].attrs['units'] = 'degrees_east'\n",
    "    output_file['time'].attrs['units'] = f'months since {start_year}-01-01'\n",
    "    output_file['monthly_masks'].attrs['units'] = '1'\n",
    "    output_file.attrs['description'] = f'Monthly masks for marine heatwaves in {region_name}'\n",
    "\n",
    "    # Save the monthly masks to a new netCDF file\n",
    "    output_file.to_netcdf(f'/Users/sayooj/Downloads/monthly_masks_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Close the netCDF files\n",
    "    masked_nc_file.close()\n",
    "\n",
    "    # Section 4: Create Consecutive Monthly Mask for Values 3 or 4\n",
    "    # Load the netCDF file containing the monthly masks\n",
    "    monthly_masks_file = xr.open_dataset(f'/Users/sayooj/Downloads/monthly_masks_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc', decode_times=False)\n",
    "\n",
    "    # Extract the monthly masks variable\n",
    "    monthly_masks_data = monthly_masks_file['monthly_masks'].values\n",
    "\n",
    "    # Initialize the consecutive monthly mask array\n",
    "    consecutive_monthly_mask = np.zeros_like(monthly_masks) * np.nan\n",
    "\n",
    "    # Iterate over each lat-lon point\n",
    "    for lat_idx in range(monthly_masks_data.shape[1]):\n",
    "        for lon_idx in range(monthly_masks_data.shape[2]):\n",
    "            # Extract the monthly mask values for the current lat-lon point\n",
    "            values = monthly_masks_data[:, lat_idx, lon_idx]\n",
    "\n",
    "            consecutive_count = 0\n",
    "            consecutive_mask = np.zeros_like(values)\n",
    "\n",
    "            for i in range(len(values)):\n",
    "                if (values[i] == 3) or (values[i] == 4):\n",
    "                    consecutive_count += 1\n",
    "                    consecutive_mask[i] = values[i]\n",
    "                else:\n",
    "                    consecutive_count = 0\n",
    "                    consecutive_mask[i] = 0\n",
    "\n",
    "                if consecutive_count >= consecutive_months_threshold:\n",
    "                    break\n",
    "\n",
    "            # Set the consecutive monthly mask values for the current lat-lon point\n",
    "            consecutive_monthly_mask[:len(consecutive_mask), lat_idx, lon_idx] = consecutive_mask\n",
    "\n",
    "    # Apply the Longhurst mask to set values inside the region to NaN\n",
    "    consecutive_monthly_mask = np.where(mask, consecutive_monthly_mask, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "    # Create a new netCDF file to save the consecutive monthly mask\n",
    "    consecutive_monthly_mask_file = xr.Dataset(\n",
    "        data_vars={\n",
    "            'lat': ('lat', monthly_masks_file['lat'].values),\n",
    "            'lon': ('lon', monthly_masks_file['lon'].values),\n",
    "            'time': ('time', monthly_masks_file['time'].values),\n",
    "            'consecutive_monthly_mask': (['time', 'lat', 'lon'], consecutive_monthly_mask)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add attributes\n",
    "    consecutive_monthly_mask_file['lat'].attrs['units'] = 'degrees_north'\n",
    "    consecutive_monthly_mask_file['lon'].attrs['units'] = 'degrees_east'\n",
    "    consecutive_monthly_mask_file['time'].attrs['units'] = f'months since {start_year}-01-01'\n",
    "    consecutive_monthly_mask_file['consecutive_monthly_mask'].attrs['units'] = '1'\n",
    "    consecutive_monthly_mask_file.attrs['description'] = f'Consecutive monthly mask for values 3 or 4 in {region_name}'\n",
    "\n",
    "    # Save the consecutive monthly mask to a new netCDF file\n",
    "    consecutive_monthly_mask_file.to_netcdf(f'/Users/sayooj/Downloads/consecutive_monthly_mask_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Close the netCDF files\n",
    "    monthly_masks_file.close()\n",
    "    consecutive_monthly_mask_file.close()\n",
    "\n",
    "    # Initialize a list to store information about consecutive heatwaves\n",
    "    consecutive_heatwave_info = []\n",
    "\n",
    "    # Iterate over each lat-lon point\n",
    "    for lat_idx in range(consecutive_monthly_mask.shape[1]):\n",
    "        for lon_idx in range(consecutive_monthly_mask.shape[2]):\n",
    "            # Extract the consecutive monthly mask values for the current lat-lon point\n",
    "            values = consecutive_monthly_mask[:, lat_idx, lon_idx]\n",
    "\n",
    "            # Find indices where consecutive heatwaves occurred (values 3 or 4)\n",
    "            heatwave_indices = np.where(np.isin(values, [3, 4]))[0]\n",
    "\n",
    "            # If consecutive heatwaves occurred at this lat-lon point\n",
    "            if len(heatwave_indices) >= consecutive_months_threshold:\n",
    "                # Get the corresponding dates for the identified indices\n",
    "                heatwave_dates = monthly_masks_file['time'].values[heatwave_indices]\n",
    "\n",
    "                # Convert months to dates based on the start_year\n",
    "                start_date = pd.to_datetime(f'{start_year}-01-01')\n",
    "                exact_dates = [(start_date + pd.DateOffset(months=int(month))).strftime('%Y-%m-%d') for month in heatwave_dates]\n",
    "\n",
    "                # Append the lat, lon, months, and exact_dates to the list\n",
    "                consecutive_heatwave_info.append({\n",
    "                    'lat': monthly_masks_file['lat'].values[lat_idx],\n",
    "                    'lon': monthly_masks_file['lon'].values[lon_idx],\n",
    "                    'months': heatwave_dates.tolist(),\n",
    "                    'exact_dates': exact_dates\n",
    "                })\n",
    "\n",
    "    # Create a DataFrame with the extracted information\n",
    "    consecutive_heatwave_info_df = pd.DataFrame(consecutive_heatwave_info)\n",
    "\n",
    "    # Save the DataFrame to a CSV file with region name, start year, and end year in the filename\n",
    "    csv_file_path = f'/Users/sayooj/Downloads/consecutive_heatwave_info_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.csv'\n",
    "    consecutive_heatwave_info_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "\n",
    "    # Section 4: Create Consecutive Monthly Mask for Values 3 or 4\n",
    "    # Load the netCDF file containing the monthly masks\n",
    "    monthly_masks_file = xr.open_dataset(f'/Users/sayooj/Downloads/monthly_masks_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc', decode_times=False)\n",
    "\n",
    "    # Extract the monthly masks variable\n",
    "    monthly_masks_data = monthly_masks_file['monthly_masks'].values\n",
    "\n",
    "    # Initialize the consecutive monthly mask array\n",
    "    consecutive_monthly_mask = np.zeros_like(monthly_masks) * np.nan\n",
    "\n",
    "    # Iterate over each lat-lon point\n",
    "    for lat_idx in range(monthly_masks_data.shape[1]):\n",
    "        for lon_idx in range(monthly_masks_data.shape[2]):\n",
    "            # Extract the monthly mask values for the current lat-lon point\n",
    "            values = monthly_masks_data[:, lat_idx, lon_idx]\n",
    "\n",
    "            consecutive_count = 0\n",
    "            consecutive_mask = np.zeros_like(values)\n",
    "\n",
    "            for i in range(len(values)):\n",
    "                if (values[i] == 3) or (values[i] == 4):\n",
    "                    consecutive_count += 1\n",
    "                    consecutive_mask[i] = values[i]\n",
    "                else:\n",
    "                    consecutive_count = 0\n",
    "                    consecutive_mask[i] = 0\n",
    "\n",
    "                if consecutive_count >= consecutive_months_threshold:\n",
    "                    break\n",
    "\n",
    "            # Set the consecutive monthly mask values for the current lat-lon point\n",
    "            consecutive_monthly_mask[:len(consecutive_mask), lat_idx, lon_idx] = consecutive_mask\n",
    "\n",
    "    # Apply the Longhurst mask to set values inside the region to NaN\n",
    "    consecutive_monthly_mask = np.where(mask, consecutive_monthly_mask, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "    # Create a new netCDF file to save the consecutive monthly mask\n",
    "    consecutive_monthly_mask_file = xr.Dataset(\n",
    "        data_vars={\n",
    "            'lat': ('lat', monthly_masks_file['lat'].values),\n",
    "            'lon': ('lon', monthly_masks_file['lon'].values),\n",
    "            'time': ('time', monthly_masks_file['time'].values),\n",
    "            'consecutive_monthly_mask': (['time', 'lat', 'lon'], consecutive_monthly_mask)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add attributes\n",
    "    consecutive_monthly_mask_file['lat'].attrs['units'] = 'degrees_north'\n",
    "    consecutive_monthly_mask_file['lon'].attrs['units'] = 'degrees_east'\n",
    "    consecutive_monthly_mask_file['time'].attrs['units'] = f'months since {start_year}-01-01'\n",
    "    consecutive_monthly_mask_file['consecutive_monthly_mask'].attrs['units'] = '1'\n",
    "    consecutive_monthly_mask_file.attrs['description'] = f'Consecutive monthly mask for values 3 or 4 in {region_name}'\n",
    "\n",
    "    # Save the consecutive monthly mask to a new netCDF file\n",
    "    consecutive_monthly_mask_file.to_netcdf(f'/Users/sayooj/Downloads/consecutive_monthly_mask_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Close the netCDF files\n",
    "    monthly_masks_file.close()\n",
    "    consecutive_monthly_mask_file.close()\n",
    "\n",
    "    # Initialize a list to store information about consecutive heatwaves\n",
    "    consecutive_heatwave_info = []\n",
    "\n",
    "    # Iterate over each lat-lon point\n",
    "    for lat_idx in range(consecutive_monthly_mask.shape[1]):\n",
    "        for lon_idx in range(consecutive_monthly_mask.shape[2]):\n",
    "            # Extract the consecutive monthly mask values for the current lat-lon point\n",
    "            values = consecutive_monthly_mask[:, lat_idx, lon_idx]\n",
    "\n",
    "            # Find indices where consecutive heatwaves occurred (values 3 or 4)\n",
    "            heatwave_indices = np.where(np.isin(values, [3, 4]))[0]\n",
    "\n",
    "            # If consecutive heatwaves occurred at this lat-lon point\n",
    "            if len(heatwave_indices) >= consecutive_months_threshold:\n",
    "                # Get the corresponding dates for the identified indices\n",
    "                heatwave_dates = monthly_masks_file['time'].values[heatwave_indices]\n",
    "\n",
    "                # Convert months to dates based on the start_year\n",
    "                start_date = pd.to_datetime(f'{start_year}-01-01')\n",
    "                exact_dates = [(start_date + pd.DateOffset(months=int(month))).strftime('%Y-%m-%d') for month in heatwave_dates]\n",
    "\n",
    "                # Append the lat, lon, months, and exact_dates to the list\n",
    "                consecutive_heatwave_info.append({\n",
    "                    'lat': monthly_masks_file['lat'].values[lat_idx],\n",
    "                    'lon': monthly_masks_file['lon'].values[lon_idx],\n",
    "                    'months': heatwave_dates.tolist(),\n",
    "                    'exact_dates': exact_dates\n",
    "                })\n",
    "\n",
    "    # Create a DataFrame with the extracted information\n",
    "    consecutive_heatwave_info_df = pd.DataFrame(consecutive_heatwave_info)\n",
    "\n",
    "    # Save the DataFrame to a CSV file with region name, start year, and end year in the filename\n",
    "    csv_file_path = f'/Users/sayooj/Downloads/consecutive_heatwave_info_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.csv'\n",
    "    consecutive_heatwave_info_df.to_csv(csv_file_path, index=False)\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    consecutive_heatwave_info_df = pd.read_csv(f'/Users/sayooj/Downloads/consecutive_heatwave_info_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.csv')\n",
    "\n",
    "    # Convert the 'exact_dates' column from string to list of datetime objects\n",
    "    consecutive_heatwave_info_df['exact_dates'] = consecutive_heatwave_info_df['exact_dates'].apply(eval)\n",
    "    consecutive_heatwave_info_df['exact_dates'] = consecutive_heatwave_info_df['exact_dates'].apply(lambda dates: [pd.to_datetime(date).date() for date in dates])\n",
    "\n",
    "    # Extract the date portion from the third date in each list of exact dates\n",
    "    third_dates = consecutive_heatwave_info_df['exact_dates'].apply(lambda dates: dates[2])\n",
    "\n",
    "    # Find the min and max date among the extracted third dates\n",
    "    hw_first_date = min(third_dates)\n",
    "    hw_last_date = max(third_dates)\n",
    "\n",
    "    # Section 4: Statistical Analysis\n",
    "    # Open the heatwave dataset file\n",
    "    heatwave_dataset_file = nc.Dataset('/Users/sayooj/Downloads/OceanSODA-ETHZ_GRaCER_v2021a_1982-2020.nc')\n",
    "\n",
    "    # Open the non-heatwave dataset file\n",
    "    non_heatwave_dataset_file = nc.Dataset('/Users/sayooj/Downloads/all_variables_monthly_avg_overall.nc')\n",
    "\n",
    "    # Get the variable data for heatwave dataset\n",
    "    variables_heatwave = ['fgco2', 'ph_total', 'omega_ar', 'temperature', 'spco2', 'talk']\n",
    "    heatwave_data = {var: heatwave_dataset_file.variables[var][:] for var in variables_heatwave}\n",
    "\n",
    "    # Get the variable data for non-heatwave dataset\n",
    "    variables_non_heatwave = ['fgco2', 'ph_total', 'omega_ar', 'temperature', 'spco2', 'talk']\n",
    "    non_heatwave_data = {var: non_heatwave_dataset_file.variables[var][:] for var in variables_non_heatwave}\n",
    "\n",
    "    # Create the time axis for the specified years\n",
    "    dates = pd.date_range(start='1982-01-01', end='2020-12-31', freq='M')  \n",
    "    \n",
    "    # Find the indices corresponding to the time period\n",
    "    start_index = (start_year - 1982) * 12\n",
    "    end_index = start_index + (end_year - start_year + 1) * 12\n",
    "\n",
    "    # Slice the data for the specified years in heatwave dataset\n",
    "    heatwave_data_year = {var: data[start_index:end_index] for var, data in heatwave_data.items()}\n",
    "\n",
    "    # Slice the data for the non-heatwave dataset for the corresponding months\n",
    "    non_heatwave_data_year = {var: data[:12] for var, data in non_heatwave_data.items()}\n",
    "\n",
    "    # Open the mask file for the specified region\n",
    "    mask_file = nc.Dataset(f'/Users/sayooj/Downloads/consecutive_monthly_mask_{region_name}{consecutive_months_threshold}_{start_year}_{end_year}.nc')\n",
    "\n",
    "    # Get the mask variable for the specified region\n",
    "    mask_region = mask_file.variables['consecutive_monthly_mask'][:]\n",
    "\n",
    "    # Get indices where the mask values are equal to any of the specified cat values (e.g., heatwave period)\n",
    "    indices_heatwave_region_year = np.where(np.isin(mask_region, combined_cat_values))[0]\n",
    "\n",
    "    # Get indices where the mask values are not equal to any of the specified cat values (e.g., non-heatwave period)\n",
    "    indices_non_heatwave_region_year = np.where(~np.isin(mask_region, combined_cat_values))[0]\n",
    "\n",
    "    # Iterate over each variable for analysis\n",
    "    for variable in variables_heatwave:\n",
    "        # Initialize a list to store results for each variable\n",
    "        results = []\n",
    "\n",
    "        # Get the data for the variable\n",
    "        variable_heatwave = heatwave_data_year[variable]\n",
    "        variable_non_heatwave = non_heatwave_data_year[variable]\n",
    "\n",
    "        # Apply the mask to the sliced data in heatwave dataset\n",
    "        variable_masked_year = np.ma.masked_array(variable_heatwave, np.logical_not(mask_region))\n",
    "\n",
    "        # Calculate the cyclic index for mask_region to match the time dimension of non-heatwave data\n",
    "        cyclic_indices = np.arange(12) % 12  # Generate cyclic indices from 0 to 11\n",
    "\n",
    "        # Synchronize dimensions of mask_region with non-heatwave data using cyclic indices\n",
    "        mask_region_synced = mask_region[cyclic_indices]\n",
    "\n",
    "        # Mask the non-heatwave dataset variables with the synchronized mask\n",
    "        variable_non_heatwave_masked_year = np.ma.masked_array(variable_non_heatwave, np.logical_not(mask_region_synced))\n",
    "\n",
    "        # Calculate median values with the mask for the variable\n",
    "        variable_median_region_year = np.ma.median(variable_masked_year, axis=(1, 2))\n",
    "        variable_non_heatwave_median_region_year = np.ma.median(variable_non_heatwave_masked_year, axis=(1, 2))\n",
    "\n",
    "        # Perform the Wilcoxon signed-rank tests\n",
    "        p_values_region_year = []\n",
    "        median_diff_region_year = []\n",
    "        std_dev_region_year = []\n",
    "\n",
    "        for _ in range(num_samples):\n",
    "            # Randomly select indices for heatwave and non-heatwave periods\n",
    "            sample_indices_region_heatwave_year = np.random.choice(indices_heatwave_region_year, len(indices_heatwave_region_year), replace=True)\n",
    "            # Randomly select indices for non-heatwave periods, ensuring they are within the valid range (0-11)\n",
    "            sample_indices_region_non_heatwave_year = np.random.choice(range(12), len(indices_heatwave_region_year), replace=True)\n",
    "\n",
    "            # Adjust indices for non-heatwave year to ensure they are within the valid range (0-11)\n",
    "            sample_indices_region_non_heatwave_year = sample_indices_region_non_heatwave_year % 12\n",
    "\n",
    "            # Filter the data based on the sampled indices\n",
    "            sample_variable_median_region_heatwave_year = variable_median_region_year[sample_indices_region_heatwave_year]\n",
    "            sample_variable_median_region_non_heatwave_year = variable_non_heatwave_median_region_year[sample_indices_region_non_heatwave_year]\n",
    "\n",
    "            # Perform the Wilcoxon signed-rank tests\n",
    "            _, p_value_region_year = wilcoxon(sample_variable_median_region_heatwave_year, sample_variable_median_region_non_heatwave_year)\n",
    "\n",
    "            # Calculate the median difference and standard deviation\n",
    "            median_diff_region_year.append(np.median(sample_variable_median_region_heatwave_year - sample_variable_median_region_non_heatwave_year))\n",
    "            std_dev_region_year.append(np.std(sample_variable_median_region_heatwave_year - sample_variable_median_region_non_heatwave_year))\n",
    "\n",
    "            # Append the p-value to the respective list\n",
    "            p_values_region_year.append(p_value_region_year)\n",
    "\n",
    "        # Calculate median p-value, median difference, and median standard deviation\n",
    "        median_p_value = np.median(p_values_region_year)\n",
    "        median_median_diff = np.median(median_diff_region_year)\n",
    "        median_std_dev = np.median(std_dev_region_year)\n",
    "\n",
    "        # Define the function to determine significance\n",
    "        def determine_significance(p_value):\n",
    "            if p_value < 0.01:\n",
    "                return \"Significant\"\n",
    "            else:\n",
    "                return \"Not Significant\"\n",
    "\n",
    "        # Determine significance\n",
    "        significance = determine_significance(median_p_value)\n",
    "        \n",
    "        results = []\n",
    "\n",
    "        # Append results to the list\n",
    "        results.append([region_name, start_year, end_year, months_after, consecutive_months_threshold, combined_cat_values, variable, median_p_value, median_median_diff, median_std_dev, significance, hw_first_date, hw_last_date])\n",
    "\n",
    "        # Extract combined category values from the first row of the 'combined_cat_values' column\n",
    "        combined_cat_values = parameters_df['combined_cat_values'].iloc[0]\n",
    "\n",
    "        # Extract the numbers from the combined_cat_values string\n",
    "        numbers = ''.join(filter(str.isdigit, combined_cat_values))\n",
    "\n",
    "        # Insert an underscore between the numbers\n",
    "        formatted_numbers = '_'.join(numbers)\n",
    "\n",
    "        # Construct the filename\n",
    "        csv_filename = f\"results_cat_{formatted_numbers}.csv\"\n",
    "\n",
    "        # Check if the file exists, if not, create it and write the header\n",
    "        if not os.path.exists(csv_filename):\n",
    "            with open(csv_filename, 'w', newline='') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                # Write header\n",
    "                csv_writer.writerow([\"Region Name\", \"Start Year\", \"End Year\", \"months_after\", \"Consecutive Months Threshold\", \"combined_cat_values\", \"Parameter\", \"Median p-value\", \"Median median difference\", \"Median standard deviation\", \"Significance\", \"HW Start Date\", \"HW End Date\"])\n",
    "\n",
    "        # Append data to CSV\n",
    "        with open(csv_filename, 'a', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            # Write data rows\n",
    "            csv_writer.writerows(results)\n",
    "\n",
    "        print(\"Results for\", variable, \"in\", region_name, \"appended to\", csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b83649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
